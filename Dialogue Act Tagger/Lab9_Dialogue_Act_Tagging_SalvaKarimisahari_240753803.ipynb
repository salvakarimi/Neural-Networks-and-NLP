{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_ZORURKg-fp"
      },
      "source": [
        "# Dialogue Act Tagging\n",
        "\n",
        "Dialogue act (DA) tagging is an essential step in the development of dialog systems. DA tagging is a problem that is usually solved using supervised machine learning techniques, which all require a large amount of manually labeled data. For DA tagging, a variety of methods have been investigated. In this lab, we'll look at two different DA classification models. The Switchboard Dialog Act Corpus is being used for training.\n",
        "Corpus can be downloaded from http://compprag.christopherpotts.net/swda.html.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwHJYYGTaBVh",
        "outputId": "a6122cd4-747d-457f-927a-c2b97150b7e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-04-23 13:45:49--  https://github.com/juntaoy/ECS7001_LAB_DATASETS/raw/refs/heads/main/DA_data.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "302 Found\n",
            "Location: https://raw.githubusercontent.com/juntaoy/ECS7001_LAB_DATASETS/refs/heads/main/DA_data.zip [following]\n",
            "--2025-04-23 13:45:49--  https://raw.githubusercontent.com/juntaoy/ECS7001_LAB_DATASETS/refs/heads/main/DA_data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14495014 (14M) [application/zip]\n",
            "Saving to: ‘DA_data.zip’\n",
            "\n",
            "DA_data.zip         100%[===================>]  13.82M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-04-23 13:45:49 (184 MB/s) - ‘DA_data.zip’ saved [14495014/14495014]\n",
            "\n",
            "Archive:  DA_data.zip\n",
            "   creating: swda/\n",
            "   creating: swda/sw10utt/\n",
            "   creating: swda/sw00utt/\n",
            "   creating: swda/sw04utt/\n",
            "  inflating: swda/.DS_Store          \n",
            "   creating: swda/sw05utt/\n",
            "   creating: swda/sw11utt/\n",
            "   creating: swda/sw01utt/\n",
            "  inflating: swda/swda-metadata.csv  \n",
            "   creating: swda/sw08utt/\n",
            "   creating: swda/sw09utt/\n",
            "   creating: swda/sw06utt/\n",
            "   creating: swda/sw12utt/\n",
            "   creating: swda/sw02utt/\n",
            "   creating: swda/sw13utt/\n",
            "   creating: swda/sw03utt/\n",
            "   creating: swda/sw07utt/\n",
            "  inflating: swda/sw10utt/sw_1029_3774.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1093_3184.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1090_2353.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1083_2959.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1011_3352.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1050_2968.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1045_2495.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1019_2898.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1004_2562.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1056_3276.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1035_2957.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1078_2437.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1055_3272.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1044_2457.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1061_4770.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1020_2935.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1054_3208.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1005_2693.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1040_3244.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1057_3293.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1074_3647.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1080_2812.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1034_2924.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1016_2471.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1009_3102.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1060_3852.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1059_3764.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1028_3496.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1084_2991.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1051_3170.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1067_2689.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1022_2982.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1000_2292.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1077_2205.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1087_3214.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1007_2993.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1021_2954.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1002_2426.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1038_3061.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1079_2511.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1014_2101.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1001_2389.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1053_3203.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1003_2524.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1063_2432.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1012_3527.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1006_2967.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1086_3057.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1092_2623.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1052_3198.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1047_2754.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1026_3280.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1032_2557.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1033_2723.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1096_3346.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1024_3247.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1042_4078.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1017_2543.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1037_3054.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1046_2621.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1073_3271.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1065_2675.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1094_3255.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1058_3711.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1098_3788.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1091_2373.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1018_2692.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1030_2064.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1076_3686.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1008_3016.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1048_2794.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1072_3270.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1082_2854.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1089_3567.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1041_3290.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1088_3230.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1066_2679.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1043_2293.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1023_3231.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1095_3257.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1070_3013.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1036_2960.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1075_3665.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1025_3250.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1068_2834.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1039_3077.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1031_2386.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1010_3226.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1013_4822.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1085_3001.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1062_2190.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1027_3463.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1015_2355.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1099_2929.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1064_2478.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1069_2884.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1049_2889.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1081_2821.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1097_3769.utt.csv  \n",
            "  inflating: swda/sw10utt/sw_1071_3162.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0005_4646.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0071_3658.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0018_4082.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0038_4611.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0030_4166.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0024_4688.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0025_2451.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0036_4379.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0012_4360.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0080_4366.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0051_4364.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0064_4346.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0001_4325.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0070_3435.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0068_3075.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0099_3917.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0063_4334.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0090_3133.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0013_4617.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0067_2945.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0002_4330.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0072_3876.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0029_4152.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0074_4127.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0056_3351.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0062_4158.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0052_4378.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0087_2775.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0048_4340.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0092_3154.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0042_4060.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0040_2095.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0020_4109.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0017_4036.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0021_4168.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0058_3707.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0049_4353.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0032_4333.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0011_4358.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0028_4133.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0084_2109.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0081_4380.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0098_3830.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0008_4321.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0057_3506.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0076_4153.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0019_4104.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0027_4096.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0041_4048.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0053_2184.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0097_3798.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0009_4329.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0003_4103.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0031_4319.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0059_4028.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0016_3389.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0094_3315.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0086_2546.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0073_4049.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0066_2593.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0065_4349.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0039_4628.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0037_4382.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0075_4129.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0023_4341.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0054_2789.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0004_4327.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0050_4362.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0083_4830.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0033_4336.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0091_3135.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0007_4171.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0034_4345.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0014_4619.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0035_4372.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0015_4877.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0085_2395.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0088_3073.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0043_4148.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0082_4626.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0078_4181.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0044_4177.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0047_4339.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0089_3086.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0079_4318.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0077_4155.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0061_4151.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0095_3445.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0010_4356.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0026_3902.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0096_3580.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0093_3227.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0069_3144.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0046_4316.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0060_4038.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0022_4320.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0045_4312.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0055_3156.utt.csv  \n",
            "  inflating: swda/sw00utt/sw_0006_4108.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0403_2650.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0462_2439.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0423_3325.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0491_3256.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0479_2910.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0410_2970.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0470_2627.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0497_3354.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0487_3206.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0445_4697.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0454_2231.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0459_2330.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0435_4008.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0406_2784.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0437_4092.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0467_2554.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0473_2658.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0447_4801.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0405_2717.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0496_3344.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0400_2558.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0416_3205.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0433_3727.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0490_3246.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0419_3284.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0458_2316.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0404_2667.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0481_3045.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0408_2860.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0452_2111.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0420_3288.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0472_2653.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0429_3607.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0414_3067.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0438_4113.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0449_4858.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0413_3041.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0494_3331.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0468_2559.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0412_3015.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0485_3099.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0446_4792.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0466_2547.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0440_4347.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0478_2896.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0486_3173.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0439_4314.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0430_3633.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0492_3259.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0461_2436.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0443_4679.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0498_3417.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0474_2691.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0499_3420.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0402_2634.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0469_2615.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0431_3655.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0495_3334.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0434_3809.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0448_4826.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0482_3068.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0493_3296.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0483_3070.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0421_3311.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0415_3168.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0432_3720.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0489_3238.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0425_3382.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0484_3085.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0465_2525.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0460_2331.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0409_2866.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0477_2868.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0427_3509.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0401_2568.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0456_2266.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0444_4682.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0441_4608.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0411_2998.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0464_2510.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0426_3409.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0457_2304.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0422_3320.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0475_2761.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0417_3237.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0424_3328.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0488_3215.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0436_4055.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0471_2640.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0407_2826.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0428_3550.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0480_3040.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0442_4649.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0476_2790.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0418_3275.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0455_2247.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0450_4886.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0463_2469.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0453_2139.utt.csv  \n",
            "  inflating: swda/sw04utt/sw_0451_2062.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0577_4659.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0571_3750.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0519_4733.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0551_3155.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0535_2501.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0568_3586.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0578_4796.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0521_2041.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0518_4691.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0514_4174.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0516_4618.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0524_2124.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0503_3539.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0564_3497.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0507_3606.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0570_3691.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0567_3574.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0522_2072.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0556_3317.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0540_2619.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0544_2800.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0576_4363.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0594_2617.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0500_3425.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0531_2365.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0547_3051.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0504_3549.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0560_3377.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0542_2782.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0555_3294.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0580_2015.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0532_2455.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0566_3551.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0541_2719.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0586_2295.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0593_2597.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0581_2032.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0537_2521.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0589_2433.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0533_2486.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0561_3406.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0572_3768.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0584_2220.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0549_3111.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0599_2870.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0543_2792.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0512_3811.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0557_3333.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0527_2177.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0554_3260.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0538_2545.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0588_2423.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0550_3124.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0569_3638.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0596_2734.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0511_3746.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0575_4114.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0508_3628.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0530_2334.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0509_3639.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0548_3074.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0536_2502.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0587_2383.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0565_3523.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0592_2533.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0595_2645.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0528_2260.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0558_3342.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0506_3576.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0591_2460.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0553_3229.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0559_3365.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0582_2051.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0585_2279.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0539_2609.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0513_3988.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0562_3443.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0525_2130.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0545_2840.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0574_4023.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0546_2913.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0510_3680.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0590_2445.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0529_2324.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0520_2010.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0579_4834.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0552_3187.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0598_2858.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0526_2160.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0523_2092.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0505_3569.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0583_2053.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0502_3525.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0534_2499.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0563_3458.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0501_3450.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0515_4184.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0573_4022.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0517_4633.utt.csv  \n",
            "  inflating: swda/sw05utt/sw_0597_2835.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1108_3533.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1100_3419.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1111_2897.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1112_3004.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1101_3693.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1110_2874.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1107_3332.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1106_3662.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1102_2820.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1114_2262.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1105_3175.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1113_2909.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1103_2915.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1109_2842.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1104_2921.utt.csv  \n",
            "  inflating: swda/sw11utt/sw_1115_3451.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0162_3801.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0195_3763.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0170_4868.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0156_3252.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0150_2628.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0112_2061.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0126_3349.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0190_3324.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0153_3138.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0100_3925.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0141_2060.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0157_3304.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0137_4370.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0191_3427.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0147_2539.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0107_4150.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0164_3862.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0159_3369.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0118_3080.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0136_4099.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0148_2604.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0167_4736.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0154_3142.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0146_2477.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0104_4101.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0168_4765.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0110_4880.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0120_3113.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0181_3146.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0109_4342.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0175_2729.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0182_3152.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0185_3174.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0131_3561.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0124_3201.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0119_3083.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0117_2837.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0155_3219.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0180_3134.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0158_3327.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0133_3796.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0187_3242.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0138_4890.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0160_3467.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0113_2093.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0166_4519.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0184_3171.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0102_4033.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0179_3120.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0152_3108.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0121_3140.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0198_3962.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0139_4908.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0116_2406.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0163_3821.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0169_4831.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0189_3266.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0188_3251.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0192_3495.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0140_4928.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0114_2107.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0123_3186.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0183_3169.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0125_3306.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0193_3508.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0111_2018.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0173_2548.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0101_4019.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0143_2290.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0145_2429.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0197_3883.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0127_3411.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0172_2305.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0199_4004.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0186_3188.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0177_2759.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0134_3887.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0178_3038.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0132_3682.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0106_4137.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0194_3595.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0108_4175.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0165_4079.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0105_4123.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0142_2145.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0171_2028.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0122_3161.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0176_2749.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0144_2399.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0130_3514.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0103_4074.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0174_2708.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0129_3476.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0161_3781.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0115_2370.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0196_3838.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0149_2611.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0128_3441.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0151_2772.utt.csv  \n",
            "  inflating: swda/sw01utt/sw_0135_4090.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0809_2040.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0894_4703.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0863_2709.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0820_2638.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0832_3265.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0836_3326.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0879_3433.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0827_3019.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0899_2325.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0833_3281.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0847_3985.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0816_2368.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0898_2303.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0870_2888.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0846_3956.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0817_2379.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0838_3405.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0853_2125.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0886_3760.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0875_3136.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0842_3657.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0837_3379.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0884_3676.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0854_2168.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0806_4774.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0860_2614.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0858_2506.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0812_2289.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0845_3754.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0888_3813.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0803_4037.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0880_3439.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0876_3158.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0807_4799.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0872_3034.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0818_2528.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0825_2953.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0811_2278.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0890_3903.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0808_2038.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0877_3166.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0871_2930.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0883_3597.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0840_3426.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0834_3282.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0849_4709.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0882_3554.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0801_3908.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0873_3042.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0891_3921.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0878_3189.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0830_3233.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0839_3424.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0893_4630.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0869_2871.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0862_2707.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0881_3500.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0828_3055.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0859_2534.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0892_3979.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0804_4165.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0823_2827.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0814_2308.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0866_2768.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0855_2191.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0829_3228.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0850_4721.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0841_3530.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0826_2981.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0819_2594.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0815_2354.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0864_2716.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0867_2770.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0897_2244.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0868_2788.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0852_2090.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0805_4758.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0802_3971.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0887_3803.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0885_3745.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0813_2296.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0848_4666.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0821_2711.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0835_3319.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0857_2483.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0856_2342.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0831_3253.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0800_3841.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0810_2232.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0865_2741.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0824_2944.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0889_3815.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0861_2684.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0851_4802.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0896_4814.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0844_3743.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0874_3059.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0822_2776.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0895_4788.utt.csv  \n",
            "  inflating: swda/sw08utt/sw_0843_3738.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0925_4681.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0904_2767.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0946_3107.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0989_3692.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0999_2227.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0939_2994.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0920_3747.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0951_3383.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0961_3770.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0995_4735.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0922_3946.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0937_2950.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0941_3014.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0954_3460.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0950_3221.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0907_2830.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0931_2467.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0971_2839.utt.csv  \n",
            "  inflating: swda/sw09utt/.DS_Store  \n",
            "  inflating: swda/sw09utt/sw_0926_2149.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0910_2955.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0919_3723.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0908_2844.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0975_3009.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0994_4644.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0981_3204.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0900_2339.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0970_2773.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0953_3457.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0952_3454.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0988_3570.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0923_4615.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0991_3855.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0913_3361.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0980_3185.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0918_3716.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0977_3104.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0935_2774.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0917_3694.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0992_3952.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0956_3521.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0998_2175.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0993_3965.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0963_4716.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0942_3025.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0949_3216.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0973_2934.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0957_3709.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0909_2879.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0983_3363.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0936_2917.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0972_2862.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0905_2780.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0962_3847.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0982_3310.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0997_2155.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0912_3267.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0990_3703.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0966_2323.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0985_3428.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0933_2662.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0914_3448.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0959_3735.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0947_3118.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0967_2340.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0924_4655.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0958_3734.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0976_3046.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0944_3064.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0969_2578.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0987_3518.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0927_2228.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0916_3642.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0915_3624.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0932_2610.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0960_3751.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0996_4745.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0979_3181.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0943_3028.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0974_2942.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0930_2446.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0938_2983.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0903_2576.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0940_2995.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0948_3151.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0965_2263.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0934_2744.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0906_2803.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0945_3076.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0929_2344.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0968_2413.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0964_2237.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0978_3167.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0902_2552.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0955_3489.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0928_2234.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0901_2418.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0911_3121.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0984_3414.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0921_3810.utt.csv  \n",
            "  inflating: swda/sw09utt/sw_0986_3455.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0631_4149.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0696_2431.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0693_2300.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0625_3573.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0635_2065.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0630_4080.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0666_3359.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0652_2797.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0657_2900.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0670_3386.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0618_3368.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0681_4147.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0646_2575.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0679_3898.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0672_3453.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0611_3072.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0697_2514.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0615_3131.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0689_2197.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0651_2766.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0636_2079.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0653_2806.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0665_3355.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0661_3194.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0695_2424.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0650_2642.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0603_2962.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0623_3537.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0663_3225.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0673_3504.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0683_4675.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0617_3353.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0656_2887.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0600_2883.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0686_4829.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0612_3090.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0604_2969.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0658_2992.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0622_3473.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0699_2519.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0648_2616.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0638_2105.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0668_3373.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0691_2283.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0616_3283.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0624_3557.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0692_2287.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0649_2620.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0645_2537.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0601_2893.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0655_2849.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0610_3056.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0659_3143.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0621_3449.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0684_4723.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0607_3012.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0602_2938.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0664_3330.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0698_2515.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0675_3675.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0629_4056.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0640_2309.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0643_2452.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0634_2027.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0682_4660.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0609_3049.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0662_3196.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0678_3845.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0605_2989.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0685_4726.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0688_2181.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0694_2380.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0687_2085.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0639_2187.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0632_4707.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0620_3408.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0619_3399.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0633_2024.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0690_2268.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0608_3030.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0676_3804.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0613_3096.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0654_2847.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0677_3805.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0660_3190.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0671_3421.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0647_2579.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0669_3381.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0642_2450.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0644_2476.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0680_3926.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0627_3651.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0674_3666.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0641_2313.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0667_3372.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0626_3596.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0606_3011.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0614_3097.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0637_2104.utt.csv  \n",
            "  inflating: swda/sw06utt/sw_0628_3773.utt.csv  \n",
            "  inflating: swda/sw12utt/sw_1210_3756.utt.csv  \n",
            "  inflating: swda/sw12utt/sw_1209_2836.utt.csv  \n",
            "  inflating: swda/sw12utt/sw_1202_2151.utt.csv  \n",
            "  inflating: swda/sw12utt/sw_1204_2434.utt.csv  \n",
            "  inflating: swda/sw12utt/sw_1201_2131.utt.csv  \n",
            "  inflating: swda/sw12utt/sw_1203_2229.utt.csv  \n",
            "  inflating: swda/sw12utt/sw_1206_2461.utt.csv  \n",
            "  inflating: swda/sw12utt/sw_1200_2121.utt.csv  \n",
            "  inflating: swda/sw12utt/sw_1207_2503.utt.csv  \n",
            "  inflating: swda/sw12utt/sw_1205_2441.utt.csv  \n",
            "  inflating: swda/sw12utt/sw_1208_2724.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0267_2362.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0205_4725.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0212_2275.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0216_2336.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0239_3367.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0265_2264.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0201_4311.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0215_2314.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0261_2120.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0251_4026.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0273_2485.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0272_2479.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0257_4876.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0283_2710.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0274_2527.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0202_4376.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0229_3130.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0245_3565.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0225_2877.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0289_2832.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0235_3232.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0223_2703.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0296_3202.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0231_3150.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0230_3148.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0264_2252.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0254_4138.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0248_3697.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0277_2598.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0290_2851.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0258_2008.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0228_3115.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0240_3387.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0262_2137.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0291_2876.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0200_4159.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0288_2828.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0246_3615.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0293_3069.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0285_2756.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0218_2465.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0268_2366.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0287_2819.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0234_3195.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0236_3235.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0280_2648.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0241_3403.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0282_2672.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0276_2565.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0269_2382.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0238_3364.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0203_4603.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0237_3279.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0250_3850.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0244_3526.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0209_2102.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0263_2226.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0214_2302.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0227_3093.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0252_4071.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0295_3200.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0297_3223.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0284_2743.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0204_4698.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0286_2785.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0211_2163.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0207_2039.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0294_3088.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0233_3182.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0222_2676.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0221_2566.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0298_3245.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0243_3513.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0217_2421.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0270_2397.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0299_3254.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0255_4548.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0226_3081.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0266_2299.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0279_2602.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0206_4859.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0224_2818.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0220_2549.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0210_2113.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0219_2472.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0271_2435.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0242_3503.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0213_2285.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0253_4072.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0208_2094.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0278_2599.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0232_3159.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0256_4728.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0292_3023.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0281_2657.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0275_2540.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0247_3660.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0249_3728.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0260_2073.utt.csv  \n",
            "  inflating: swda/sw02utt/sw_0259_2020.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1325_4384.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1317_3942.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1320_4002.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1315_3924.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1323_4167.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1308_2753.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1312_3469.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1310_3035.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1321_4102.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1319_3994.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1318_3968.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1304_2632.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1316_3936.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1326_4622.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1313_3520.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1309_2838.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1303_2567.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1307_2752.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1322_4157.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1305_2702.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1314_3528.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1302_2505.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1324_4179.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1311_3129.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1300_2335.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1306_2733.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1328_4771.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1301_2347.utt.csv  \n",
            "  inflating: swda/sw13utt/sw_1327_4643.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0363_3487.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0385_2012.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0342_2956.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0378_4154.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0390_2241.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0383_4812.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0334_2587.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0366_3517.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0391_2259.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0325_2171.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0397_2492.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0376_4077.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0348_3062.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0352_3236.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0304_3338.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0337_2608.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0331_2488.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0313_3825.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0399_2526.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0379_4483.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0354_3286.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0309_3663.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0305_3343.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0394_2427.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0358_3362.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0377_4130.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0361_3398.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0371_3688.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0319_4642.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0347_3052.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0389_2157.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0336_2603.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0340_2678.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0396_2490.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0338_2641.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0332_2571.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0308_3646.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0306_3345.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0300_3268.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0355_3300.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0333_2584.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0301_3269.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0351_3207.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0388_2078.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0373_4013.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0362_3447.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0341_2932.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0369_3584.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0324_2154.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0322_4936.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0328_2349.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0381_4784.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0350_3103.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0372_3725.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0330_2466.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0387_2067.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0353_3239.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0329_2372.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0312_3784.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0370_3636.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0382_4785.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0393_2407.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0326_2249.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0395_2442.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0360_3397.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0335_2589.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0364_3491.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0365_3515.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0384_2005.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0380_4572.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0317_4064.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0302_3309.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0343_2965.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0367_3524.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0357_3360.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0315_3993.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0368_3541.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0392_2405.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0356_3303.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0303_3313.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0307_3375.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0316_4051.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0374_4032.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0321_4902.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0398_2504.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0314_3983.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0386_2035.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0323_2022.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0311_3776.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0359_3393.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0346_3047.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0345_3021.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0318_4565.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0375_4050.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0310_3699.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0327_2253.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0344_3020.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0349_3082.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0320_4720.utt.csv  \n",
            "  inflating: swda/sw03utt/sw_0339_2669.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0763_3402.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0702_2652.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0793_3095.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0779_2301.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0775_2006.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0746_2448.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0737_2110.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0715_3092.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0760_3291.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0722_3791.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0739_2180.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0773_4821.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0720_3696.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0756_3063.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0751_2793.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0710_2996.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0736_2071.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0704_2690.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0707_2755.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0733_4940.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0761_3340.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0765_3535.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0799_3828.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0797_3563.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0728_4759.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0769_3659.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0741_2221.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0742_2235.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0719_3587.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0714_3039.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0770_3681.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0771_3870.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0724_3802.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0759_3191.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0785_2647.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0745_2387.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0776_2086.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0725_3911.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0740_2185.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0789_2999.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0757_3071.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0791_3050.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0762_3371.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0712_3029.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0787_2926.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0726_4443.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0795_3429.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0798_3736.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0767_3591.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0708_2927.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0711_3007.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0784_2630.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0717_3384.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0734_2019.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0781_2482.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0700_2586.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0731_4917.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0723_3797.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0786_2875.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0788_2984.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0758_3087.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0754_3003.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0778_2248.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0768_3626.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0705_2713.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0772_4752.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0716_3105.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0794_3234.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0727_4605.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0743_2265.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0749_2726.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0796_3464.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0766_3556.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0721_3777.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0782_2570.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0744_2376.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0747_2585.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0709_2952.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0718_3543.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0703_2661.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0777_2122.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0738_2178.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0730_4905.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0774_4856.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0706_2751.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0713_3036.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0780_2393.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0764_3431.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0735_2025.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0792_3065.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0732_4927.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0783_2622.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0750_2736.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0729_4840.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0748_2663.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0790_3002.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0753_3000.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0755_3018.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0701_2631.utt.csv  \n",
            "  inflating: swda/sw07utt/sw_0752_2963.utt.csv  \n"
          ]
        }
      ],
      "source": [
        "!wget 'https://github.com/juntaoy/ECS7001_LAB_DATASETS/raw/refs/heads/main/DA_data.zip'\n",
        "!unzip DA_data.zip -x __MACOSX/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziKyA9R4gyw9"
      },
      "source": [
        "The downloaded dataset should be kept in a data folder in the same directory as this file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tqdm in /home/ubuntu/.local/lib/python3.10/site-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jmTpKt_uefe5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
        "\n",
        "import glob\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn.metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook as tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6E8axaw1hAbM"
      },
      "outputs": [],
      "source": [
        "f = glob.glob(\"swda/sw*/sw*.csv\")\n",
        "frames = []\n",
        "for i in range(0, len(f)):\n",
        "    frames.append(pd.read_csv(f[i]))\n",
        "\n",
        "result = pd.concat(frames, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7hKGF7EhM4s",
        "outputId": "612eeece-59d2-4974-e665-f9f6b93f385a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of converations in the dataset: 223606\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of converations in the dataset:\",len(result))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ttyB2lQhc7B"
      },
      "source": [
        "The dataset has many different features, we are only using act_tag and text for this training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-jUifIdshhD0"
      },
      "outputs": [],
      "source": [
        "reduced_df = result[['act_tag','text']]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iPmZvysqg2i"
      },
      "source": [
        "Reduce the number of tags to 43 by combining them and converting them to generic tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MQuHm0jPt_lz"
      },
      "outputs": [],
      "source": [
        "# Imported from \"https://github.com/cgpotts/swda\"\n",
        "# Convert the combination tags to the generic 43 tags\n",
        "\n",
        "import re\n",
        "def damsl_act_tag(input):\n",
        "        \"\"\"\n",
        "        Seeks to duplicate the tag simplification described at the\n",
        "        Coders' Manual: http://www.stanford.edu/~jurafsky/ws97/manual.august1.html\n",
        "        \"\"\"\n",
        "        d_tags = []\n",
        "        tags = re.split(r\"\\s*[,;]\\s*\", input)\n",
        "        for tag in tags:\n",
        "            if tag in ('qy^d', 'qw^d', 'b^m'): pass\n",
        "            elif tag == 'nn^e': tag = 'ng'\n",
        "            elif tag == 'ny^e': tag = 'na'\n",
        "            else:\n",
        "                tag = re.sub(r'(.)\\^.*', r'\\1', tag)\n",
        "                tag = re.sub(r'[\\(\\)@*]', '', tag)\n",
        "                if tag in ('qr', 'qy'):                         tag = 'qy'\n",
        "                elif tag in ('fe', 'ba'):                       tag = 'ba'\n",
        "                elif tag in ('oo', 'co', 'cc'):                 tag = 'oo_co_cc'\n",
        "                elif tag in ('fx', 'sv'):                       tag = 'sv'\n",
        "                elif tag in ('aap', 'am'):                      tag = 'aap_am'\n",
        "                elif tag in ('arp', 'nd'):                      tag = 'arp_nd'\n",
        "                elif tag in ('fo', 'o', 'fw', '\"', 'by', 'bc'): tag = 'fo_o_fw_\"_by_bc'\n",
        "            d_tags.append(tag)\n",
        "        # Dan J says (p.c.) that it makes sense to take the first;\n",
        "        # there are only a handful of examples with 2 tags here.\n",
        "        return d_tags[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8N_PUCAblq3",
        "outputId": "8b07d593-cb52-44ab-fc94-b2389afa5ebf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_7496/1040889475.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  reduced_df[\"act_tag\"] = reduced_df[\"act_tag\"].apply(lambda x: damsl_act_tag(x))\n"
          ]
        }
      ],
      "source": [
        "reduced_df[\"act_tag\"] = reduced_df[\"act_tag\"].apply(lambda x: damsl_act_tag(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UNy0vvhhqpD"
      },
      "source": [
        "This dataset contains 43 tags. Yes-No-Question ('qy'), Statement-non-opinion ('sd'), and Statement-opinion ('sv') are some of the tags. Tags information can be found here http://compprag.christopherpotts.net/swda.html#tags.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dR1rKmkh9QG"
      },
      "source": [
        "You can check the frequency of tags."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9biiyP8UiGDe"
      },
      "source": [
        "To get unique tags:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "BrhW8gyLfQQK"
      },
      "outputs": [],
      "source": [
        "unique_tags = set()\n",
        "for tag in reduced_df['act_tag']:\n",
        "    unique_tags.add(tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LMOX5KwgiPmu"
      },
      "outputs": [],
      "source": [
        "tag_dict = {t:i for i,t in enumerate(list(unique_tags))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZPHPCxE3iPby"
      },
      "outputs": [],
      "source": [
        "tags_encoding = []\n",
        "for i in range(0, len(reduced_df)):\n",
        "    tags_encoding.append(tag_dict[reduced_df['act_tag'].iloc[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVI8QyVzjqWh"
      },
      "source": [
        "The tags are one hot encoded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQJTiffPjUtu"
      },
      "source": [
        "To create sentence embeddings:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PmkyD1TfjWGO"
      },
      "outputs": [],
      "source": [
        "sentences = []\n",
        "for i in range(0, len(reduced_df)):\n",
        "    sentences.append(reduced_df['text'].iloc[i].split(\" \"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MlD6L6e3jV-7"
      },
      "outputs": [],
      "source": [
        "wordvectors = {}\n",
        "index = 1\n",
        "for s in sentences:\n",
        "    for w in s:\n",
        "        if w not in wordvectors:\n",
        "            wordvectors[w] = index\n",
        "            index += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LX6DidEvjVWs"
      },
      "outputs": [],
      "source": [
        "sentence_embeddings = []\n",
        "for s in sentences:\n",
        "    sentence_emb = []\n",
        "    for w in s:\n",
        "        sentence_emb.append(wordvectors[w])\n",
        "    sentence_embeddings.append(sentence_emb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr4iEyNTjmlu"
      },
      "source": [
        "The dataset is divided into two sections: test and training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "GiNZ-iI_jnOF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "X_train, X_test, y_train, y_test = train_test_split(sentence_embeddings, np.array(tags_encoding),shuffle=False, stratify=None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RqMeWe_jron"
      },
      "source": [
        "Pad each utterance to make them all the same length.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yqD7DvzRGRY7"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 150"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfA5x2ocfZwY",
        "outputId": "f022c86d-af16-494c-8d06-b25b9ed40803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 19, 22, 23, 24, 24, 4, 25, 26, 27, 24, 6] 32\n"
          ]
        }
      ],
      "source": [
        "print(X_train[1],y_train[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Ai9cwv82jufe"
      },
      "outputs": [],
      "source": [
        "def pad_sequences(sequences, maxlen):\n",
        "    return [seq[:maxlen] + [0] * (maxlen - len(seq)) for seq in sequences]\n",
        "\n",
        "train_sentences_X = pad_sequences(X_train, maxlen=MAX_LENGTH)\n",
        "test_sentences_X = pad_sequences(X_test, maxlen=MAX_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "517zYSQLXkbn"
      },
      "outputs": [],
      "source": [
        "# Split Train into Train and Validation - about 10% into validation - In order to validate the model as it is training\n",
        "\n",
        "train_input = train_sentences_X[:140000]\n",
        "val_input = train_sentences_X[140000:]\n",
        "\n",
        "train_labels = y_train[:140000]\n",
        "val_labels = y_train[140000:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igsWGlltd9Bs",
        "outputId": "df60f475-705e-4818-afa2-67dd0c1bed6d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([105,   6,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(train_input[11052])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMHV2AoseXYT",
        "outputId": "1312a282-0849-472d-d626-7640f27c100b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[105, 6]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentence_embeddings[11052]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "An0ABdxeUkpO",
        "outputId": "6c193ae8-66d1-4089-8837-6803492176fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels[11052]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHJbZDtk7N-3"
      },
      "source": [
        "# Model 1 -\n",
        "\n",
        "This first model has an architecture of:\n",
        "\n",
        "- Embedding  \n",
        "- BLSTM  \n",
        "- Fully Connected Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FItlHC1Fjz6y"
      },
      "source": [
        "The model architecture is as follows: Embedding Layer (to generate word\n",
        "embeddings). Next layer Bidirectional LSTM. Feed forward layer with number of neurons = number of tags.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "M97Sw5iv-lEU"
      },
      "outputs": [],
      "source": [
        "VOCAB_SIZE = len(wordvectors)+1 # 43,731\n",
        "EMBED_SIZE = 100 # arbitary\n",
        "HIDDEN_SIZE = len(unique_tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCaX-ptaj8G2",
        "outputId": "098480f9-b640-4b3b-c446-a6c95b11d867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BiLSTMModel(\n",
            "  (embedder): Embedding(43732, 100)\n",
            "  (lstm1): LSTM(100, 43, batch_first=True, bidirectional=True)\n",
            "  (lstm2): LSTM(86, 43, batch_first=True, bidirectional=True)\n",
            "  (dense): Linear(in_features=86, out_features=43, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class BiLSTMModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Task 1 1/4\n",
        "\n",
        "    Begin\n",
        "    \"\"\"\n",
        "    def __init__(self,vocab_size, embed_size, hidden_size, max_length):\n",
        "        super(BiLSTMModel, self).__init__()\n",
        "\n",
        "        # Include 2 BLSTM layers, in order to capture both the forward and backward hidden states\n",
        "\n",
        "        # Embedding layer\n",
        "        # Bidirectional 1\n",
        "        # Bidirectional 2\n",
        "        # Dense layer\n",
        "\n",
        "        self.embedder= nn.Embedding(vocab_size, embed_size)\n",
        "\n",
        "        self.lstm1 = nn.LSTM(input_size=embed_size, hidden_size=hidden_size,\n",
        "                        batch_first=True, bidirectional=True)\n",
        "\n",
        "        self.lstm2 = nn.LSTM(input_size=2*hidden_size, hidden_size=hidden_size,\n",
        "                        batch_first=True, bidirectional=True)\n",
        "\n",
        "        self.dense = nn.Linear(2 * hidden_size, hidden_size)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x shape: (batch_size, seq_length)\n",
        "        \"\"\"\n",
        "        out2 = self.embedder(x)\n",
        "        out2, _ = self.lstm1(out2)\n",
        "        out2, _ = self.lstm2(out2)\n",
        "\n",
        "        # sentence_representation = x[:, -1, :]\n",
        "        # probs = self.dense_layer(sentence_representation)\n",
        "\n",
        "        # return probs\n",
        "\n",
        "        idx = (x != 0).sum(1).clamp(min=1) - 1\n",
        "\n",
        "        out = out2[torch.arange(out2.size(0)), idx]\n",
        "\n",
        "        return self.dense(out)\n",
        "    \"\"\"\n",
        "    End Task 1 1/4\n",
        "    \"\"\"\n",
        "\n",
        "# Instantiate the model\n",
        "model = BiLSTMModel(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embed_size=EMBED_SIZE,\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    max_length=MAX_LENGTH\n",
        ")\n",
        "# Print model summary (PyTorch-style)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VQfGROIeoLH6"
      },
      "outputs": [],
      "source": [
        "train_input_t = torch.Tensor(train_input)\n",
        "train_labels_t = torch.Tensor(train_labels)\n",
        "val_input_t = torch.Tensor(val_input)\n",
        "val_labels_t = torch.Tensor(val_labels)\n",
        "test_sentences_X_t = torch.Tensor(test_sentences_X)\n",
        "y_test_t = torch.Tensor(y_test)\n",
        "\n",
        "train_dataset = TensorDataset(train_input_t, train_labels_t)\n",
        "val_dataset = TensorDataset(val_input_t, val_labels_t)\n",
        "test_dataset = TensorDataset(test_sentences_X_t, y_test_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "OeiLkgD3Arpl"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dataset, val_dataset, epoch_num, lr, batch_size=1, device=\"cpu\", weight=None):\n",
        "    model.train()\n",
        "    model = model.to(device)\n",
        "    if weight:\n",
        "       weight = torch.Tensor(weight).to(device)\n",
        "    criterion = nn.CrossEntropyLoss(weight=weight).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    for epoch in range(epoch_num):\n",
        "      model.train()\n",
        "      total_loss = 0.0\n",
        "      correct = 0\n",
        "      \"\"\"\n",
        "      Task 1 2/3\n",
        "\n",
        "      Begin\n",
        "      \"\"\"\n",
        "      for batch_x, batch_y in train_loader:\n",
        "\n",
        "          batch_x = batch_x.to(torch.int32).to(device)\n",
        "          batch_y = batch_y.type(torch.LongTensor).to(device)\n",
        "\n",
        "\n",
        "          # calculate the loss\n",
        "          # backpropagation\n",
        "          # compute the training accuracy\n",
        "\n",
        "          #perform fwd pass\n",
        "          outputs = model(batch_x)\n",
        "          loss = criterion(outputs, batch_y.long())\n",
        "          optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          total_loss += loss.item()\n",
        "          predicted = torch.argmax(outputs,dim = 1)\n",
        "          correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      avg_loss = total_loss / len(train_dataset)\n",
        "      accuracy = correct / len(train_dataset)\n",
        "\n",
        "      # Validation\n",
        "      model.eval()\n",
        "      val_loss = 0.0\n",
        "      val_correct = 0\n",
        "      with torch.no_grad():\n",
        "          for val_x, val_y in val_loader:\n",
        "              val_x = val_x.to(torch.int32).to(device)\n",
        "              val_y = val_y.type(torch.LongTensor).to(device)\n",
        "\n",
        "              # calculate the validation loss\n",
        "              # calculate the validation accuracy\n",
        "\n",
        "              outputs = model(val_x)\n",
        "              loss = criterion(outputs, val_y.long())\n",
        "              val_loss += loss.item()\n",
        "              predicted = torch.argmax(outputs,dim = 1)\n",
        "              val_correct += (predicted == val_y).sum().item()\n",
        "\n",
        "\n",
        "\n",
        "      \"\"\"\n",
        "      End Task 1 2/3\n",
        "      \"\"\"\n",
        "      val_loss /= len(val_dataset)\n",
        "      val_accuracy = val_correct / len(val_dataset)\n",
        "\n",
        "      print(f\"Epoch [{epoch+1}/{epoch_num}] \"\n",
        "            f\"Train Loss: {avg_loss:.4f}, Train Acc: {accuracy:.4f} | \"\n",
        "            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtsWmz00nX8j",
        "outputId": "3d6e4db5-f9d5-400b-cce1-27f30ce56423"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5] Train Loss: 0.0030, Train Acc: 0.7634 | Val Loss: 0.0040, Val Acc: 0.6946\n",
            "Epoch [2/5] Train Loss: 0.0028, Train Acc: 0.7736 | Val Loss: 0.0040, Val Acc: 0.6913\n",
            "Epoch [3/5] Train Loss: 0.0027, Train Acc: 0.7855 | Val Loss: 0.0041, Val Acc: 0.6891\n",
            "Epoch [4/5] Train Loss: 0.0026, Train Acc: 0.7956 | Val Loss: 0.0041, Val Acc: 0.6890\n",
            "Epoch [5/5] Train Loss: 0.0024, Train Acc: 0.8056 | Val Loss: 0.0042, Val Acc: 0.6803\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "train(model, train_dataset, val_dataset, 5, 1e-3, 256, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "9bu0taSOVmVx"
      },
      "outputs": [],
      "source": [
        "def eval(model, test_dataset, batch_size=1, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "    test_loss = 0.0\n",
        "    test_correct = 0\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for test_x, test_y in test_loader:\n",
        "            test_x = test_x.to(torch.int32).to(device)\n",
        "            test_y = test_y.type(torch.LongTensor).to(device)\n",
        "\n",
        "            \"\"\"\n",
        "            Task 1 3/3\n",
        "\n",
        "            Begin\n",
        "            \"\"\"\n",
        "\n",
        "            # calculate the test loss\n",
        "            # calculate the test accuracy\n",
        "            outputs = model(test_x)\n",
        "            loss = criterion(outputs, test_y)\n",
        "            test_loss += loss.item()\n",
        "            predicted = torch.argmax(outputs,dim = 1)\n",
        "            test_correct += (predicted == test_y).sum().item()\n",
        "\n",
        "            \"\"\"\n",
        "            End Task 1 3/3\n",
        "            \"\"\"\n",
        "\n",
        "\n",
        "    test_loss /= len(test_dataset)\n",
        "    test_accuracy = test_correct / len(test_dataset)\n",
        "\n",
        "    print(f\"Overall Loss: {test_loss:.4f}, Acc: {test_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LkONUKQkSrL",
        "outputId": "fcbf7d4c-fe1a-4bf2-a151-10a1ab12d1d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Loss: 0.0102, Acc: 0.6964\n"
          ]
        }
      ],
      "source": [
        "eval(model, test_dataset, 100, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhMViQVSPY1J"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHwoVCEwjEz7"
      },
      "source": [
        "You should look at the accuracy of some minority classes in addition to overall accuracy. Signal-non-understanding ('br') is a good indicator of \"other-repair,\" or situations in which the other conversational participant tries to correct the speaker's mistake. In dialogue summarization, the term \"summarize/reformulate\" ('bf') has been used. Report on the system's accuracy in predicting these classes, as well as any common errors you notice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7owA1f27se8"
      },
      "source": [
        "## Minority Classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "UZ8BwgDxNcIr"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Task 2 1/2\n",
        "\n",
        "Begin\n",
        "\"\"\"\n",
        "# Generate predictions for the test data\n",
        "def predict(model, test_dataset, batch_size=100, device=\"cpu\"):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    all_predictions = []\n",
        "    with torch.no_grad():\n",
        "        for test_x, test_y in test_loader:\n",
        "            test_x = test_x.to(torch.int32).to(device)\n",
        "\n",
        "            outputs = model(test_x)\n",
        "            all_predictions.append(outputs)\n",
        "\n",
        "\n",
        "    #stack all batch outputs into a tensor\n",
        "    output = torch.cat(all_predictions, dim=0)\n",
        "    return output.detach().cpu().numpy()\n",
        "\n",
        "label_pred = predict(model, test_dataset, 100, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I26g20qQdzF",
        "outputId": "a6fb4074-9d37-42e3-cf1f-7a726550929c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Build the confusion matrix off these predictions\n",
        "matrix = confusion_matrix(y_test, np.argmax(label_pred, axis=1))\n",
        "matrix[35][35]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGqmkjllwBBX",
        "outputId": "2500e27b-c79c-425c-bd21-cfa64bcf16c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class '%' → Accuracy: 94.86% (830/875)\n",
            "Class '^2' → Accuracy: 53.58% (299/558)\n",
            "Class '^q' → Accuracy: 29.55% (65/220)\n",
            "Class 'aa' → Accuracy: 3.70% (5/135)\n",
            "Class 'aap_am' → Accuracy: 6.80% (14/206)\n",
            "Class 'ad' → Accuracy: 27.10% (781/2882)\n",
            "Class 'b' → Accuracy: 30.20% (45/149)\n",
            "Class 'ba' → Accuracy: 76.35% (397/520)\n",
            "Class 'bd' → Accuracy: 19.05% (4/21)\n",
            "Class 'bh' → Accuracy: 5.56% (1/18)\n",
            "Class 'bk' → Accuracy: 73.68% (767/1041)\n",
            "Class 'fa' → Accuracy: 93.35% (323/346)\n",
            "Class 'fc' → Accuracy: 71.30% (3352/4701)\n",
            "Class 'fo_o_fw_\"_by_bc' → Accuracy: 22.31% (56/251)\n",
            "Class 'ft' → Accuracy: 64.67% (227/351)\n",
            "Class 'h' → Accuracy: 85.08% (15380/18078)\n",
            "Class 'ng' → Accuracy: 1.94% (3/155)\n",
            "Class 'nn' → Accuracy: 1.19% (4/335)\n",
            "Class 'no' → Accuracy: 28.30% (15/53)\n",
            "Class 'ny' → Accuracy: 1.10% (2/181)\n",
            "Class 'qh' → Accuracy: 76.94% (2823/3669)\n",
            "Class 'qo' → Accuracy: 70.42% (862/1224)\n",
            "Class 'qw^d' → Accuracy: 45.45% (30/66)\n",
            "Class 'qy' → Accuracy: 2.48% (20/805)\n",
            "Class 'qy^d' → Accuracy: 23.32% (87/373)\n",
            "Class 'sv' → Accuracy: 36.36% (32/88)\n",
            "Class 't1' → Accuracy: 68.73% (178/259)\n",
            "Class 't3' → Accuracy: 94.81% (8843/9327)\n",
            "Class 'x' → Accuracy: 48.82% (3841/7867)\n"
          ]
        }
      ],
      "source": [
        "for idx in range(len(matrix)):\n",
        "    correct_preds = matrix[idx][idx]\n",
        "    if correct_preds > 0:\n",
        "        total = matrix[idx].sum()\n",
        "        acc = correct_preds / total if total > 0 else 0.0\n",
        "        tag = list(sorted(unique_tags))[idx]\n",
        "        print(f\"Class '{tag}' → Accuracy: {acc:.2%} ({correct_preds}/{total})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "muWtF2t0W0zd",
        "outputId": "4f947ec7-b948-4ae4-cc41-a8afe451a544"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "br accuracy: 0.36363636363636365\n",
            "bf accuracy: 0.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nEnd Task 2 1/2\\n'"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Calculate Accuracies for \"br\" and \"bf\"\n",
        "\n",
        "def per_class_accuracy(confusion_matrix,class_idx):\n",
        "  correct = confusion_matrix[class_idx][class_idx]\n",
        "  total = sum(confusion_matrix[class_idx])\n",
        "  return correct/total\n",
        "\n",
        "index_br = tag_dict['br']\n",
        "iindex_bf = tag_dict['bf']\n",
        "\n",
        "print(\"br accuracy: \" + str(per_class_accuracy(matrix,index_br)))\n",
        "print(\"bf accuracy: \" + str(per_class_accuracy(matrix,iindex_bf)))\n",
        "\n",
        "\"\"\"\n",
        "End Task 2 1/2\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4s-0brg-Lh2",
        "outputId": "649d5e28-b3e7-46bb-f99c-6f74bf648066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train label frequencies: Counter({24: 57325, 41: 29054, 42: 18660, 20: 13990, 31: 12013, 8: 8275, 17: 3756, 32: 3536, 0: 2803, 36: 2235, 2: 2027, 13: 1470, 19: 1032, 21: 971, 37: 936, 27: 882, 23: 876, 40: 798, 12: 742, 3: 698, 1: 654, 26: 575, 7: 546, 29: 508, 6: 443, 5: 437, 11: 408, 33: 259, 30: 214, 39: 211, 10: 210, 25: 160, 35: 159, 28: 157, 38: 101, 22: 87, 16: 85, 9: 83, 34: 76, 14: 72, 4: 66, 15: 59, 18: 55})\n",
            "Most predicted tag: Counter({24: 21141, 41: 12254, 42: 6606, 20: 4458, 31: 3426, 8: 1404, 32: 1330, 17: 1327, 0: 865, 13: 665, 19: 594, 2: 382, 23: 338, 40: 234, 21: 205, 37: 197, 5: 89, 11: 72, 36: 57, 39: 51, 35: 46, 7: 37, 27: 30, 26: 29, 6: 25, 28: 22, 29: 7, 16: 6, 14: 5})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "print(\"Train label frequencies:\", Counter(y_train))\n",
        "print(\"Most predicted tag:\", Counter(np.argmax(label_pred, axis=1)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdnpWLggZ-6z"
      },
      "source": [
        "## Minority Classes\n",
        "\n",
        "\n",
        "\n",
        "Minority classes are frequently misidentified as majority classes, owing to the fact that majority classes have significantly more data and thus can be trained on. With 33 percent and 17 percent, respectively, the classes \"sd\" (40) and \"b\" (10) are the most common here.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUXH7H8IRpwi"
      },
      "source": [
        "## Minority Class showcase\n",
        "The frequencies of the data are plotted in the graph below. This illustrates how some classes are common, while the majority of classes are rare.\n",
        "\n",
        "Only 0.13 percent of the data belongs to the \"br\" class, while 0.42 percent belongs to the \"bf\" class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onujyCDk-_s2",
        "outputId": "8c24ca7f-474c-4a5b-9cd2-d126d0edd53f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bf frequency: 0.42977379855638936%\n",
            "br frequency: 0.13371734211067682%\n"
          ]
        }
      ],
      "source": [
        "# Print the frequency of the \"br\" and \"bf\" classes\n",
        "value_counts = reduced_df[\"act_tag\"].value_counts()\n",
        "bf_frequency = value_counts[\"bf\"]/sum(value_counts)\n",
        "print(\"bf frequency: \" + str(bf_frequency*100) + \"%\")\n",
        "\n",
        "br_frequency = value_counts[\"br\"]/sum(value_counts)\n",
        "print(\"br frequency: \" + str(br_frequency*100) + \"%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "zIr0fSSaR51s",
        "outputId": "103ea878-6638-4f68-ed82-8a26922fe4b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0xfe6a0bbbe440>]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the frequencies of the classes\n",
        "plt.figure(figsize=(15,6))\n",
        "plt.plot(value_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ16sE5F7x9e"
      },
      "source": [
        "# Model 2 - Balanced Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKHbOs4WkFaP"
      },
      "source": [
        "\n",
        "As the dataset is highly imbalanced, we can simply weight up the minority classes proportionally to their underrepresentation while training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L4kNdf6kGEa",
        "outputId": "73c4f3c1-377b-4a84-e26f-81149651a15c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 6.11062225  4.27291663  0.33159926 50.00134168 17.16217668 47.27399577\n",
            "  3.97260469  6.91507917  5.27397519 44.44563705 50.4867916   5.41117537\n",
            "  7.54737233  2.61313544 25.12144703 24.76256921 23.11173127 18.18230607\n",
            " 66.66845558  1.09246629  1.41384979  7.12347881 49.52513843  0.13548734\n",
            "  2.01165939  4.25543333  8.9967812   7.91497646  4.23809253 55.91547887\n",
            "  3.77368616  9.33597762  0.06896462  0.27821623 65.82455107  1.71057222\n",
            "  0.19603195 17.39177102 65.00174419  1.08403993  0.46608762 15.07286822\n",
            "  4.91971574]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(tags_encoding), y=tags_encoding)\n",
        "print(class_weights)\n",
        "d_class_weights = dict(enumerate(class_weights))\n",
        "d_class_weights = list(d_class_weights.values())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF1UM-ZMZoa1"
      },
      "source": [
        "## Define & Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xIRgRAzOPSAZ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Task 2 2/2\n",
        "\n",
        "Begin\n",
        "\"\"\"\n",
        "# Instantiate the model\n",
        "model_balanced = BiLSTMModel(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embed_size=EMBED_SIZE,\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    max_length=MAX_LENGTH\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "xB2McUREkL4B",
        "outputId": "aa0789d1-9c77-49e0-c3f5-40d0913f08c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20] Train Loss: 0.0116, Train Acc: 0.2899 | Val Loss: 0.0102, Val Acc: 0.3741\n",
            "Epoch [2/20] Train Loss: 0.0084, Train Acc: 0.3655 | Val Loss: 0.0090, Val Acc: 0.3420\n",
            "Epoch [3/20] Train Loss: 0.0069, Train Acc: 0.3861 | Val Loss: 0.0088, Val Acc: 0.3624\n",
            "Epoch [4/20] Train Loss: 0.0061, Train Acc: 0.4078 | Val Loss: 0.0088, Val Acc: 0.3588\n",
            "Epoch [5/20] Train Loss: 0.0054, Train Acc: 0.4169 | Val Loss: 0.0087, Val Acc: 0.4040\n",
            "Epoch [6/20] Train Loss: 0.0048, Train Acc: 0.4361 | Val Loss: 0.0089, Val Acc: 0.3817\n",
            "Epoch [7/20] Train Loss: 0.0043, Train Acc: 0.4468 | Val Loss: 0.0091, Val Acc: 0.3300\n",
            "Epoch [8/20] Train Loss: 0.0040, Train Acc: 0.4667 | Val Loss: 0.0093, Val Acc: 0.4125\n",
            "Epoch [9/20] Train Loss: 0.0036, Train Acc: 0.4870 | Val Loss: 0.0098, Val Acc: 0.3921\n",
            "Epoch [10/20] Train Loss: 0.0033, Train Acc: 0.5011 | Val Loss: 0.0104, Val Acc: 0.4315\n",
            "Epoch [11/20] Train Loss: 0.0031, Train Acc: 0.5142 | Val Loss: 0.0104, Val Acc: 0.3902\n",
            "Epoch [12/20] Train Loss: 0.0028, Train Acc: 0.5303 | Val Loss: 0.0108, Val Acc: 0.4650\n",
            "Epoch [13/20] Train Loss: 0.0027, Train Acc: 0.5493 | Val Loss: 0.0110, Val Acc: 0.4629\n",
            "Epoch [14/20] Train Loss: 0.0025, Train Acc: 0.5680 | Val Loss: 0.0114, Val Acc: 0.4446\n",
            "Epoch [15/20] Train Loss: 0.0023, Train Acc: 0.5785 | Val Loss: 0.0115, Val Acc: 0.4364\n",
            "Epoch [16/20] Train Loss: 0.0022, Train Acc: 0.5935 | Val Loss: 0.0119, Val Acc: 0.4739\n",
            "Epoch [17/20] Train Loss: 0.0021, Train Acc: 0.6041 | Val Loss: 0.0125, Val Acc: 0.4926\n",
            "Epoch [18/20] Train Loss: 0.0021, Train Acc: 0.6126 | Val Loss: 0.0126, Val Acc: 0.4992\n",
            "Epoch [19/20] Train Loss: 0.0020, Train Acc: 0.6213 | Val Loss: 0.0125, Val Acc: 0.4949\n",
            "Epoch [20/20] Train Loss: 0.0019, Train Acc: 0.6389 | Val Loss: 0.0133, Val Acc: 0.4738\n"
          ]
        }
      ],
      "source": [
        "# Train the balanced network - Seems to take long time to achieve good accuracy?\n",
        "train(model_balanced, train_dataset, val_dataset, 20, 1e-3, 256, device, d_class_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "zqTOciKeB39l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counter({34: 25648, 1: 16501, 18: 10216, 17: 1347, 40: 1282, 13: 674, 33: 107, 0: 87, 26: 40})\n"
          ]
        }
      ],
      "source": [
        "from collections import Counter\n",
        "preds = np.argmax(label_pred, axis=1)\n",
        "print(Counter(preds))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJPjlMclZtw2"
      },
      "source": [
        "## Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "8UMAMGpJRINC"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall Loss: 0.0159, Acc: 0.4953\n"
          ]
        }
      ],
      "source": [
        "# Overall Accuracy\n",
        "eval(model_balanced, test_dataset, 100, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "qkULcz2igEW3"
      },
      "outputs": [],
      "source": [
        "# Generate predictions for the test data\n",
        "label_pred = predict(model_balanced, test_dataset, 100, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hq7i7giWZ4_l"
      },
      "source": [
        "## Balanced network evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fM7VWweco0Et"
      },
      "source": [
        "Report the overall accuracy and the accuracy of  'br' and 'bf'  classes. Suggest other ways to handle imbalanced classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "def per_class_accuracy(confusion_matrix,class_idx):\n",
        "  correct = confusion_matrix[class_idx][class_idx]\n",
        "  total = sum(confusion_matrix[class_idx])\n",
        "  return correct/total\n",
        "\n",
        "index_br = tag_dict['br']\n",
        "iindex_bf = tag_dict['bf']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "4jNfWmSNgRvT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "br accuracy: 0.4318181818181818\n",
            "bf accuracy: 0.1520912547528517\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nEnd Task 2 2/2\\n'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Build the confusion matrix off these predictions\n",
        "preds = np.argmax(label_pred, axis=1)\n",
        "matrix_balanced = confusion_matrix(y_test, preds)\n",
        "\n",
        "# Calculate Accuracies for \"br\" and \"bf\"\n",
        "print(\"br accuracy: \" + str(per_class_accuracy(matrix_balanced,index_br)))\n",
        "print(\"bf accuracy: \" + str(per_class_accuracy(matrix_balanced,iindex_bf)))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "End Task 2 2/2\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zi9GyVUvPcrF"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "### Explanation\n",
        "\n",
        "\n",
        "\n",
        "### Other ways to handle imbalanced classes\n",
        "\n",
        "\n",
        "- The model can be turned into multiple single-class classifiers, giving a confidence score for each of the classes. Instead of just taking the highest confidence class, the model can run the individual classifiers in ascending order of frequency of the classes in the training corpus.  The first classifier to classify the data point over a certain confidence threshold determines the class given to the example. This gives chance for the minority class classifiers to classify before the frequent classes arrive with their more confident predicitions.\n",
        "\n",
        "- Transfer Learning could also be implemented, to initialise weights on a larger dataset, where these minority classes may be prevelant. This would allow fine-tuning with the small data for this particular application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW4g5mQkkaFv"
      },
      "source": [
        "Can we improve things by using context information?  Next we try to build a model which predicts DA tag from the sequence of\n",
        "previous DA tags, plus the utterance representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfrGWuZ6nk4y"
      },
      "source": [
        "# Using Context for Dialog Act Classification\n",
        "We expect there is valuable sequential information among the DA tags. So in this section we apply a BiLSTM on top of the sentence CNN representation. The CNN model learns textual information in each utterance for DA classification. Here, we use bidirectional-LSTM (BLSTM) to learn the context before and after the current utterance.\n",
        "\n",
        "To make it easier to train, we combined all of the utterances into one long sequence rather than breaking them up into individual dialogues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz693CIUvcca"
      },
      "source": [
        "## Define the model\n",
        "\n",
        "This model has an architecture of:\n",
        "\n",
        "- Word Embedding\n",
        "- CNN\n",
        "- Bidirectional LSTM\n",
        "- Fully-Connected output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4e0g9BdWjZF"
      },
      "source": [
        "## CNN\n",
        "\n",
        "\n",
        "This is classical CNN layer used to convolve over embedings tensor and gether useful information from it. The data is represented by hierarchy of features, which can be modelled using a CNN. We transform/reshape conv output to 2d matrix. Then we pass it to the max pooling layer that applies the max pool operation on windows of different sizes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuJLqgjWqcIf"
      },
      "source": [
        "## BiLSTM\n",
        "\n",
        "This is used to create LSTM layers. The data we’re working with has temporal properties which we want to model as well — hence the use of a LSTM. You should create a BiLSTM.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU0Xa3QOqwS3"
      },
      "source": [
        "Concatenate 2 last layers and create the output layer\n",
        "network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "9hMj-KaKvfHb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CNN_BiLSTM(\n",
            "  (embedding): Embedding(43732, 100)\n",
            "  (conv_blocks): ModuleList(\n",
            "    (0): Sequential(\n",
            "      (0): Conv2d(1, 64, kernel_size=(3, 100), stride=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (1): Sequential(\n",
            "      (0): Conv2d(1, 64, kernel_size=(4, 100), stride=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (2): Sequential(\n",
            "      (0): Conv2d(1, 64, kernel_size=(5, 100), stride=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "  )\n",
            "  (dense_1): Linear(in_features=192, out_features=100, bias=True)\n",
            "  (dropout_1): Dropout(p=0.2, inplace=False)\n",
            "  (blstm1): LSTM(100, 100, batch_first=True, bidirectional=True)\n",
            "  (blstm2): LSTM(200, 100, batch_first=True, bidirectional=True)\n",
            "  (dense_2): Linear(in_features=200, out_features=100, bias=True)\n",
            "  (dropout_2): Dropout(p=0.2, inplace=False)\n",
            "  (output): Linear(in_features=200, out_features=43, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "filter_sizes = [3,4,5]\n",
        "num_filters = 64\n",
        "drop = 0.2\n",
        "VOCAB_SIZE = len(wordvectors)+1 # 43,731\n",
        "MAX_LENGTH = 150\n",
        "EMBED_SIZE = 100 # arbitary\n",
        "HIDDEN_SIZE = len(unique_tags)\n",
        "\n",
        "class CNN_BiLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, filter_sizes, num_filters, dropout=0.2):\n",
        "        super(CNN_BiLSTM, self).__init__()\n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_size)\n",
        "\n",
        "        # Convolution blocks (Conv2D + BatchNorm + ReLU), one per filter size\n",
        "        self.conv_blocks = nn.ModuleList([\n",
        "            nn.Sequential(\n",
        "                nn.Conv2d(in_channels=1,\n",
        "                          out_channels=num_filters,\n",
        "                          kernel_size=(fs, embed_size),  # (filter_size, embedding_dim)\n",
        "                          stride=1,\n",
        "                          padding=0),\n",
        "                nn.BatchNorm2d(num_filters),\n",
        "                nn.ReLU()\n",
        "            ) for fs in filter_sizes\n",
        "        ])\n",
        "\n",
        "        # After max pooling each convolution output, we concatenate them.\n",
        "        # The shape after concatenation will be [batch_size, len(filter_sizes), 1, num_filters].\n",
        "        # We'll flatten it to [batch_size, 1, len(filter_sizes)*num_filters].\n",
        "\n",
        "        # First Dense layer (Dense_1) that maps CNN outputs down to EMBED_SIZE\n",
        "        self.dense_1 = nn.Linear(num_filters * len(filter_sizes), embed_size)\n",
        "        self.dropout_1 = nn.Dropout(dropout)\n",
        "\n",
        "        # Two stacked BiLSTM layers\n",
        "        # - The first BiLSTM has EMBED_SIZE hidden units, bidirectional => output_dim=2*EMBED_SIZE\n",
        "        # - The second BiLSTM takes 2*EMBED_SIZE as input (from the first BiLSTM if return_sequences=True).\n",
        "        #   Since it's bidirectional, final output_dim of the second BiLSTM is 2*EMBED_SIZE as well.\n",
        "        self.blstm1 = nn.LSTM(input_size=embed_size, hidden_size=embed_size,\n",
        "                              batch_first=True, bidirectional=True)\n",
        "        self.blstm2 = nn.LSTM(input_size=2*embed_size, hidden_size=embed_size,\n",
        "                              batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Second Dense layer (Dense_2) after the second BiLSTM\n",
        "        # This projects 2*EMBED_SIZE down to EMBED_SIZE\n",
        "        self.dense_2 = nn.Linear(2 * embed_size, embed_size)\n",
        "        self.dropout_2 = nn.Dropout(dropout)\n",
        "\n",
        "        # Final output layer (Output)\n",
        "        self.output = nn.Linear(embed_size + embed_size, hidden_size)  # concatenating two EMBED_SIZE vectors\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        x shape: [batch_size, MAX_LENGTH]\n",
        "        \"\"\"\n",
        "        # 1) Embedding\n",
        "        x = self.embedding(x)               # [batch_size, MAX_LENGTH, EMBED_SIZE]\n",
        "        x = x.unsqueeze(1)                  # [batch_size, 1, MAX_LENGTH, EMBED_SIZE] so we can apply Conv2D\n",
        "\n",
        "        # 2) Parallel Convolutions -> BN -> ReLU -> MaxPool\n",
        "        # Each conv_block expects input of shape [batch_size, 1, MAX_LENGTH, EMBED_SIZE].\n",
        "        pooled_outputs = []\n",
        "        for conv in self.conv_blocks:\n",
        "            conv_out = conv(x)  # shape: [batch_size, num_filters, (MAX_LENGTH - fs + 1), 1]\n",
        "            # Perform 2D max pooling across the variable spatial dimension conv_out.shape[2] and width=1\n",
        "            # This collapses each feature map to a single value per filter.\n",
        "            pooled = F.max_pool2d(conv_out, kernel_size=(conv_out.shape[2], conv_out.shape[3]))\n",
        "            # Now shape: [batch_size, num_filters, 1, 1]\n",
        "            pooled_outputs.append(pooled)\n",
        "\n",
        "        \"\"\"\n",
        "        Task 3 1/2\n",
        "\n",
        "        Begin\n",
        "        \"\"\"\n",
        "\n",
        "        # Concatenate along the channel dimension (num_filters dimension)\n",
        "        # After pooling, each block has shape [batch_size, num_filters, 1, 1].\n",
        "        # concatenation => [batch_size, len(filter_sizes)*num_filters, 1, 1]\n",
        "        x_cat = torch.cat(pooled_outputs, dim=1)\n",
        "\n",
        "        # 3) Flatten to [batch_size, 1, len(filter_sizes)*num_filters]\n",
        "        x_cat = x_cat.view(x_cat.size(0), 1, -1)\n",
        "\n",
        "\n",
        "        # 4) Dense_1 + Dropout\n",
        "        cnn_repr = self.dropout_1(self.dense_1(x_cat))\n",
        "\n",
        "        # 5) BiLSTM_1 (return_sequences=True)\n",
        "        #    Input shape: [batch_size, sequence_len, EMBED_SIZE]\n",
        "        #    Output shape: [batch_size, sequence_len, 2*EMBED_SIZE]\n",
        "        out, _ = self.blstm1(cnn_repr)\n",
        "\n",
        "        # 6) BiLSTM_2 (no return_sequences => final hidden state)\n",
        "        #    Input shape: [batch_size, sequence_len, 2*EMBED_SIZE]\n",
        "        #    final_timestep shape: [2, batch_size, EMBED_SIZE]\n",
        "        out2, (h_n, c_n) = self.blstm2(out)\n",
        "\n",
        "        #getting final hidden states and concatenating them\n",
        "        blstm_repr = torch.cat((h_n[0], h_n[1]), dim=1)\n",
        "        # 7) Dense_2 + Dropout\n",
        "\n",
        "        blstm_out = self.dropout_2(self.dense_2(blstm_repr))\n",
        "\n",
        "        # 8) Concatenate Flatten(dropout_1) and dropout_2\n",
        "        #    Flatten(dropout_1) => shape [batch_size, EMBED_SIZE]\n",
        "        #    out => [batch_size, EMBED_SIZE]\n",
        "        # Note: dropout_1 was [batch_size, 1, EMBED_SIZE], so flatten the second dimension:\n",
        "\n",
        "        cnn_flat = cnn_repr.squeeze(1)\n",
        "        combined = torch.cat((cnn_flat, blstm_out), dim=1) \n",
        "        # 9) Output layer\n",
        "        logits = self.output(combined)\n",
        "\n",
        "        \"\"\"\n",
        "        End Task 3 1/2\n",
        "        \"\"\"\n",
        "        return logits\n",
        "\n",
        "model_context = CNN_BiLSTM(\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    embed_size=EMBED_SIZE,\n",
        "    hidden_size=HIDDEN_SIZE,\n",
        "    filter_sizes=filter_sizes,\n",
        "    num_filters=num_filters,\n",
        "    dropout=drop\n",
        ")\n",
        "print(model_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxlRv9dDrcy5"
      },
      "source": [
        "Report your overall accuracy. Did context help disambiguate and better predict the minority classes ('br' and 'bf')? What are frequent errors? Show one positive example where adding context changed the prediction.\n",
        "layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "hYxHsBvwZRA4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5] Train Loss: 0.0043, Train Acc: 0.6677 | Val Loss: 0.0043, Val Acc: 0.6584\n",
            "Epoch [2/5] Train Loss: 0.0038, Train Acc: 0.7019 | Val Loss: 0.0041, Val Acc: 0.6699\n",
            "Epoch [3/5] Train Loss: 0.0035, Train Acc: 0.7199 | Val Loss: 0.0040, Val Acc: 0.6752\n",
            "Epoch [4/5] Train Loss: 0.0032, Train Acc: 0.7354 | Val Loss: 0.0041, Val Acc: 0.6731\n",
            "Epoch [5/5] Train Loss: 0.0031, Train Acc: 0.7486 | Val Loss: 0.0040, Val Acc: 0.6822\n",
            "Overall Loss: 0.0159, Acc: 0.4953\n",
            "br accuracy: 0.38636363636363635\n",
            "bf accuracy: 0.0\n",
            "Sentence index: 6\n",
            "True label: %\n",
            "Base model prediction: fc\n",
            "Context model prediction: %\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nEnd Task 3 2/2\\n'"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Task 3 2/2\n",
        "\n",
        "Begin\n",
        "\"\"\"\n",
        "train(model_context, train_dataset=train_dataset,val_dataset=val_dataset,epoch_num=5,lr=1e-3,batch_size=256,device=device,weight=None)\n",
        "eval(model_balanced, test_dataset, 100, device)\n",
        "\n",
        "label_pred_context = predict(model_context, test_dataset, batch_size=256, device=device)\n",
        "preds_context = np.argmax(label_pred_context, axis=1)\n",
        "matrix_context = confusion_matrix(y_test, preds_context)\n",
        "\n",
        "# Calculate Accuracies for \"br\" and \"bf\"\n",
        "print(\"br accuracy: \" + str(per_class_accuracy(matrix_context,index_br)))\n",
        "print(\"bf accuracy: \" + str(per_class_accuracy(matrix_context,iindex_bf)))\n",
        "\n",
        "#samples\n",
        "inv_tag_dict = {v: k for k, v in tag_dict.items()}\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    if preds[i] != y_test[i] and preds_context[i] == y_test[i]:\n",
        "        print(f\"Sentence index: {i}\")\n",
        "        print(f\"True label: {inv_tag_dict[y_test[i]]}\")\n",
        "        print(f\"Base model prediction: {inv_tag_dict[preds[i]]}\")\n",
        "        print(f\"Context model prediction: {inv_tag_dict[preds_context[i]]}\")\n",
        "        break\n",
        "\"\"\"\n",
        "End Task 3 2/2\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 'na' → Accuracy: 0.00% (0/197)\n",
            "Class 'qy^d' → Accuracy: 6.27% (21/335)\n",
            "Class '%' → Accuracy: 73.21% (2686/3669)\n",
            "Class 'bd' → Accuracy: 28.57% (6/21)\n",
            "Class 'ng' → Accuracy: 7.87% (7/89)\n",
            "Class 'oo_co_cc' → Accuracy: 21.74% (5/23)\n",
            "Class 'bk' → Accuracy: 42.09% (157/373)\n",
            "Class 'ad' → Accuracy: 14.56% (30/206)\n",
            "Class '^q' → Accuracy: 1.23% (3/244)\n",
            "Class 't3' → Accuracy: 12.50% (2/16)\n",
            "Class 't1' → Accuracy: 33.33% (6/18)\n",
            "Class 'bf' → Accuracy: 0.00% (0/263)\n",
            "Class 'b^m' → Accuracy: 1.10% (2/181)\n",
            "Class 'qw' → Accuracy: 74.42% (387/520)\n",
            "Class 'arp_nd' → Accuracy: 0.00% (0/47)\n",
            "Class 'qrr' → Accuracy: 71.70% (38/53)\n",
            "Class 'fp' → Accuracy: 40.91% (27/66)\n",
            "Class 'no' → Accuracy: 1.32% (1/76)\n",
            "Class 'ft' → Accuracy: 21.74% (5/23)\n",
            "Class 'qy' → Accuracy: 69.61% (852/1224)\n",
            "Class 'x' → Accuracy: 93.94% (822/875)\n",
            "Class '^2' → Accuracy: 6.45% (10/155)\n",
            "Class 'aap_am' → Accuracy: 0.00% (0/29)\n",
            "Class 'b' → Accuracy: 93.66% (8736/9327)\n",
            "Class 'fc' → Accuracy: 51.08% (285/558)\n",
            "Class 'fo_o_fw_\"_by_bc' → Accuracy: 7.17% (18/251)\n",
            "Class 'qh' → Accuracy: 8.15% (11/135)\n",
            "Class 'qo' → Accuracy: 43.18% (95/220)\n",
            "Class 'h' → Accuracy: 62.96% (221/351)\n",
            "Class '^g' → Accuracy: 28.57% (6/21)\n",
            "Class 'nn' → Accuracy: 94.80% (328/346)\n",
            "Class '^h' → Accuracy: 33.56% (50/149)\n",
            "Class 'sd' → Accuracy: 88.01% (15910/18078)\n",
            "Class '+' → Accuracy: 66.65% (3133/4701)\n",
            "Class 'fa' → Accuracy: 23.08% (3/13)\n",
            "Class 'ny' → Accuracy: 16.65% (134/805)\n",
            "Class 'sv' → Accuracy: 40.37% (3176/7867)\n",
            "Class 'br' → Accuracy: 38.64% (34/88)\n",
            "Class 'qw^d' → Accuracy: 0.00% (0/21)\n",
            "Class 'ba' → Accuracy: 69.26% (721/1041)\n",
            "Class 'aa' → Accuracy: 25.85% (745/2882)\n",
            "Class 'ar' → Accuracy: 0.00% (0/86)\n",
            "Class 'bh' → Accuracy: 65.64% (170/259)\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(matrix_context)):\n",
        "    class_name = inv_tag_dict[i]\n",
        "    correct = matrix_context[i][i]\n",
        "    total = matrix_context[i].sum()\n",
        "    if total > 0:\n",
        "        accuracy = correct / total * 100\n",
        "        print(f\"Class '{class_name}' → Accuracy: {accuracy:.2f}% ({correct}/{total})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fixed by Context Model:\n",
            " Sentence: Excuse me. /\n",
            " True Label:      br\n",
            " Base Predicted:  ad\n",
            " Context Predicted: br\n",
            "\n",
            "Fixed by Context Model:\n",
            " Sentence: Pardon me. /\n",
            " True Label:      br\n",
            " Base Predicted:  qy^d\n",
            " Context Predicted: br\n",
            "\n",
            "Fixed by Context Model:\n",
            " Sentence: <Throat_clearing> The ones that what? /\n",
            " True Label:      br\n",
            " Base Predicted:  qy^d\n",
            " Context Predicted: br\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# index → word\n",
        "reversed_wordvectors = {v: k for k, v in wordvectors.items()} \n",
        "# index → tag \n",
        "index_to_tag = {v: k for k, v in tag_dict.items()}             \n",
        "\n",
        "preds_base = np.argmax(label_pred, axis=1)\n",
        "preds_context = np.argmax(label_pred_context, axis=1)\n",
        "\n",
        "for i in range(len(y_test)):\n",
        "    gold = y_test[i]\n",
        "    base = preds_base[i]\n",
        "    context = preds_context[i]\n",
        "\n",
        "    tag = index_to_tag[gold]\n",
        "\n",
        "    # 'br' or 'bf' sentences that were misclassified by base, but correctly by context\n",
        "    if gold == context and base != gold and tag in [\"br\", \"bf\"]:\n",
        "        tokens = [reversed_wordvectors.get(w, \"<UNK>\") for w in test_sentences_X[i] if w != 0]\n",
        "        sentence = \" \".join(tokens)\n",
        "\n",
        "        print(f\"Fixed by Context Model:\")\n",
        "        print(f\" Sentence: {sentence}\")\n",
        "        print(f\" True Label:      {tag}\")\n",
        "        print(f\" Base Predicted:  {index_to_tag[base]}\")\n",
        "        print(f\" Context Predicted: {index_to_tag[context]}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
