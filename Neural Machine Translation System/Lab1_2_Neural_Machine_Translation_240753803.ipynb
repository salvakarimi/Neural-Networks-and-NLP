{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZfqzG-psHbd"
      },
      "source": [
        "# Neural Machine Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9GBwu1PsSR3"
      },
      "source": [
        "This week and the next, we will build a neural machine translation model based on the sequence-to-sequence (seq2seq) models proposed by Sutskever et al., 2014 and Cho et al., 2014. The seq2seq model is widely used in Machine Translation systems such as Google’s neural machine translation system (GNMT) (Wu et al., 2016).\n",
        "\n",
        "In today’s lab and the one next week, we will explore the seq2seq model, as well as attention in machine translation.\n",
        "\n",
        "For training and evaluating our mode, we will use the English-Vietnamese parallel corpus of TED talks provided by the IWSLT Evaluation Campaign. For our tasks, we will translate from Vietnamese into English.\n",
        "\n",
        "The parallel corpus has been provided for you:\n",
        "1. **data.30.vi** - a file where each line contains a Vietnamese sentence to be translated (i.e. the source sentences)\n",
        "2. **data.30.en** - a file where each line contains an English sentence corresponding to the Vietnamese sentence in the same line position. (i.e. the target sentences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8V5YoFP3yQO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40cd9094-5ac3-4b11-b158-70f10fb8ff2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-16 19:06:31--  https://github.com/juntaoy/ECS7001_LAB_DATASETS/raw/refs/heads/main/NMT_data.zip\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/juntaoy/ECS7001_LAB_DATASETS/refs/heads/main/NMT_data.zip [following]\n",
            "--2025-03-16 19:06:31--  https://raw.githubusercontent.com/juntaoy/ECS7001_LAB_DATASETS/refs/heads/main/NMT_data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4815130 (4.6M) [application/zip]\n",
            "Saving to: ‘NMT_data.zip.8’\n",
            "\n",
            "\rNMT_data.zip.8        0%[                    ]       0  --.-KB/s               \rNMT_data.zip.8      100%[===================>]   4.59M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2025-03-16 19:06:31 (141 MB/s) - ‘NMT_data.zip.8’ saved [4815130/4815130]\n",
            "\n",
            "Archive:  NMT_data.zip\n",
            "replace data.30.en? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace data.30.vi? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://github.com/juntaoy/ECS7001_LAB_DATASETS/raw/refs/heads/main/NMT_data.zip'\n",
        "!unzip NMT_data.zip -x __MACOSX/*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nG711LZurbd"
      },
      "source": [
        "Let's first install the `Sacrebleu` (https://github.com/mjpost/sacrebleu) package for BLEU computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BunTKYx-urbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cdfa1ca-5a04-4d78-fc21-5618b1a130f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.1.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-7n3ObOurbd"
      },
      "source": [
        "## Overview\n",
        "This script defines a total of three classes: the main class (`NmtModel`), the attention layer class (`AttentionLayer`) and a helper class (`LanguageDict`). The `NmtModel` class contains most of the code of the NMT system and is the one you are asked to complete for Task 1 and 2. The `AttentionLayer` class is a custom layer to implement the attention mechanism, Task 3 is to finish this class. `LanguageDict` is a class that stores resources related to languages, such as vocab, word2ids, etc. The code for this class is provided."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Xy5t3L6Vurbe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import collections\n",
        "import numpy as np\n",
        "import time\n",
        "from sacrebleu import corpus_bleu\n",
        "\n",
        "SOURCE_PATH = 'data.30.vi'\n",
        "TARGET_PATH = 'data.30.en'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVfxreW3urbe"
      },
      "source": [
        "## The `LanguageDict` class stores the language resources\n",
        "This class has only an initialisation method. The method takes a corpus as the input and builds the vocab and word2ids for the language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Jb0dKAXyurbe"
      },
      "outputs": [],
      "source": [
        "class LanguageDict():\n",
        "  def __init__(self, sents):\n",
        "    word_counter = collections.Counter(tok.lower() for sent in sents for tok in sent)\n",
        "\n",
        "    self.vocab = []\n",
        "    self.vocab.append('<pad>') #zero paddings\n",
        "    self.vocab.append('<unk>')\n",
        "    # add only words that appear at least 10 times in the corpus\n",
        "    self.vocab.extend([t for t,c in word_counter.items() if c > 10])\n",
        "\n",
        "    self.word2ids = {w:id for id, w in enumerate(self.vocab)}\n",
        "    self.UNK = self.word2ids['<unk>']\n",
        "    self.PAD = self.word2ids['<pad>']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htl6d7_2urbe"
      },
      "source": [
        "## The `load_dataset()` method creates train/dev/test batches\n",
        "The method reads the given file and loads the first max_num_examples sentences and split them into train/dev/test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RoSEMVHeurbe"
      },
      "outputs": [],
      "source": [
        "def pad_sequences(seq_list, max_len=None, pad_value=0):\n",
        "    \"\"\"\n",
        "    A simple PyTorch-like pad_sequences function.\n",
        "    seq_list: List of lists of token IDs.\n",
        "    max_len : If None, will use the length of the longest sequence.\n",
        "    pad_value: ID to use for padding.\n",
        "    Returns a 2D NumPy array with shape [batch_size, max_length].\n",
        "    \"\"\"\n",
        "    if max_len is None:\n",
        "        max_len = max(len(seq) for seq in seq_list)\n",
        "    padded = []\n",
        "    for seq in seq_list:\n",
        "        seq = seq[:max_len]\n",
        "        padded.append(seq + [pad_value]*(max_len - len(seq)))\n",
        "    return np.array(padded)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(source_path,target_path, max_num_examples=30000):\n",
        "  ''' This helper method reads from the source and target files to load max_num_examples\n",
        "  sentences split them into train, development and testing and return relevant data.\n",
        "  Inputs:\n",
        "    source_path (string): the full path to the source data, SOURCE_PATHf\n",
        "    target_path (string): the full path to the target data, TARGET_PATH\n",
        "  Returns:\n",
        "    train_data (list): a list of 3 elements: source_words, target words, target word labels\n",
        "    dev_data (list): a list of 2 elements - source words, target word labels\n",
        "    test_data (list): a list of 2 elements - source words, target word labels\n",
        "    source_dict (LanguageDict): a LanguageDict object for the source language, Vietnamese.\n",
        "    target_dict (LanguageDict): a LanguageDict object for the target language, English.\n",
        "  '''\n",
        "  # source_lines/target lines are list of strings\n",
        "  # such that each string is a sentence in the corresponding file\n",
        "  source_lines = open(source_path).readlines()\n",
        "  target_lines = open(target_path).readlines()\n",
        "  assert len(source_lines) == len(target_lines)\n",
        "  if max_num_examples > 0:\n",
        "    max_num_examples = min(len(source_lines), max_num_examples)\n",
        "    source_lines = source_lines[:max_num_examples]\n",
        "    target_lines = target_lines[:max_num_examples]\n",
        "\n",
        "  # strip trailing/leading whitespaces and tokenize each sentence\n",
        "  source_sents = [[tok.lower() for tok in sent.strip().split(' ')] for sent in source_lines]\n",
        "  target_sents = [[tok.lower() for tok in sent.strip().split(' ')] for sent in target_lines]\n",
        "  # for the target sentences, add <start> and <end> tokens to each sentence\n",
        "  for sent in target_sents:\n",
        "    sent.append('<end>')\n",
        "    sent.insert(0,'<start>')\n",
        "\n",
        "  # create the LanguageDict objects for each file\n",
        "  source_lang_dict = LanguageDict(source_sents)\n",
        "  target_lang_dict = LanguageDict(target_sents)\n",
        "\n",
        "\n",
        "  # for the source sentences:\n",
        "  # we'll use this proportion to split into train/dev/test\n",
        "  unit = len(source_sents)//10\n",
        "  # get the sents-as-ids for each sentence\n",
        "  source_words = [[source_lang_dict.word2ids.get(tok,source_lang_dict.UNK) for tok in sent] for sent in source_sents]\n",
        "  # 8 parts (80%) of the sentences go to the training data and are padded up to the maximum sentence length\n",
        "  source_words_train = pad_sequences(source_words[:8*unit])\n",
        "  # 1 part (10%) of the sentences go to the dev data and are padded up to the up to the maximum sentence length\n",
        "  source_words_dev = pad_sequences(source_words[8*unit:9*unit])\n",
        "  # 1 part (10%) of the sentences go to the test dataand are padded up to the up to the maximum sentence length\n",
        "  source_words_test = pad_sequences(source_words[9*unit:])\n",
        "\n",
        "\n",
        "  eos = target_lang_dict.word2ids['<end>']\n",
        "  # for each sentence, get the word index for the tokens from <start> to up to but not including <end>,\n",
        "  target_words = [[target_lang_dict.word2ids.get(tok,target_lang_dict.UNK) for tok in sent[:-1]] for sent in target_sents]\n",
        "  # select the training set and pad the sentences\n",
        "  target_words_train = pad_sequences(target_words[:8*unit])\n",
        "  # the label for each target word is the next word, we also add <end> as the last token\n",
        "  target_words_train_labels = [sent[1:]+[eos] for sent in target_words[:8*unit]]\n",
        "  # pad the labels. Dim = [num_sents, max_sent_length]\n",
        "  target_words_train_labels = pad_sequences(target_words_train_labels)\n",
        "  # expand one dimension at the end for the loss computation. Dim = [num_sents, max_sent_length, 1].\n",
        "  target_words_train_labels = np.expand_dims(target_words_train_labels,axis=2)\n",
        "\n",
        "  # get the labels for the dev and test data. No need for inputs here and no need to expand dimensions\n",
        "  target_words_dev_labels = pad_sequences([sent[1:] + [eos] for sent in target_words[8 * unit:9 * unit]])\n",
        "  target_words_test_labels = pad_sequences([sent[1:] + [eos] for sent in target_words[9 * unit:]])\n",
        "\n",
        "  # our final data\n",
        "  train_data = [source_words_train,target_words_train,target_words_train_labels]\n",
        "  dev_data = [source_words_dev,target_words_dev_labels]\n",
        "  test_data = [source_words_test,target_words_test_labels]\n",
        "\n",
        "  return train_data,dev_data,test_data,source_lang_dict,target_lang_dict"
      ],
      "metadata": {
        "id": "PVWToO9UVhrg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtVUJHAeurbe"
      },
      "source": [
        "## The `AttentionLayer` class creates a custom layer for attention\n",
        "\n",
        "The class takes two inputs: the `encoder_outputs` and the `decoder_outputs` and returns a `new_decoder_outputs` that leverages the `decoder_outputs` with the `encoder_outputs`.\n",
        "\n",
        "This class contains three methods. The first one is used for passing the mask to the next layer. The mask is originally created by the `Embedding` layer with the `mask_zero` attribute set to `True`, so that the padding is not taken into account in the computations of loss or by LSTM layers. So, in this first method we return the mask for the `decoder_outputs`. The second method computes the output shape of our layer. The output shape of the layer is the same to the `decoder_outputs` in the first two dimensions and for the last dimension the embedding dimension is doubled.\n",
        "\n",
        "The third method is the main method for the layer, and also the one you will need to implement for your Task 3. We will come back to this later.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9ruSjILDurbf"
      },
      "outputs": [],
      "source": [
        "class AttentionLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Custom layer implementing Luong attention.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "\n",
        "    def forward(self, encoder_outputs, decoder_outputs):\n",
        "        \"\"\"\n",
        "        encoder_outputs : [batch_size, max_source_length, hidden_size]\n",
        "        decoder_outputs : [batch_size, max_target_length, hidden_size]\n",
        "        \"\"\"\n",
        "\n",
        "        if encoder_outputs is None or decoder_outputs is None:\n",
        "            raise ValueError(\"encoder_outputs or decoder_outputs is None.\")\n",
        "\n",
        "        batch_size, max_source_len, hidden_size = encoder_outputs.shape\n",
        "        _, max_target_len, _ = decoder_outputs.shape\n",
        "\n",
        "        #transposing decoder outputs to match encoder shape\n",
        "        decoder_outputs_t = decoder_outputs.permute(0, 2, 1)  # [batch_size, hidden_size, max_target_length]\n",
        "\n",
        "        #computing attention scores with dot product\n",
        "        luong_score = torch.bmm(encoder_outputs, decoder_outputs_t)  # [batch_size, max_source_length, max_target_length]\n",
        "\n",
        "        #applying a softmax to obtain attention weights\n",
        "        attention_weights = F.softmax(luong_score, dim=1)  # Normalize over source sequence\n",
        "\n",
        "        #computing the context vector as a weighted sum of encoder outputs\n",
        "        attention_weights = attention_weights.permute(0, 2, 1).unsqueeze(-1)  # [batch, max_target_length, max_source_length, 1]\n",
        "        encoder_outputs_exp = encoder_outputs.unsqueeze(1)  # [batch, 1, max_source_length, hidden_size]\n",
        "\n",
        "        encoder_vector = torch.sum(attention_weights * encoder_outputs_exp, dim=2)  # [batch, max_target_length, hidden_size]\n",
        "\n",
        "        #ensuring decoder_outputs and encoder_vector have the same length\n",
        "        min_len = min(decoder_outputs.shape[1], encoder_vector.shape[1])\n",
        "        decoder_outputs = decoder_outputs[:, :min_len, :]\n",
        "        encoder_vector = encoder_vector[:, :min_len, :]\n",
        "\n",
        "        #concating context vector with decoder outputs\n",
        "        new_decoder_outputs = torch.cat([decoder_outputs, encoder_vector], dim=-1)\n",
        "\n",
        "        print(\"attention decoder outputs shape:\", new_decoder_outputs.shape)\n",
        "        return new_decoder_outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl_67I-aurbf"
      },
      "source": [
        "## NmtModel class `__init__()` method: initialises the network parameters.\n",
        "\n",
        "This method takes three arguments. The first two are instances of `LanguageDict`, one for the source language (Vietnamese) and one for the target language (English); the third argument is a boolean variable (`use_attention`) that indicates which model (attention/basic) should be used.\n",
        "\n",
        "It then creates all the layers will be used in later stages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Implement the Embedding Layers and the Encoder\n",
        "In this task, you will work at the beginning of the `__init__()` and `forward()` method. You will need to first create two `nn.Embedding` layers (one for the source language and one for the target language). Then pass the source embedding into an `nn.LSTM` layer.\n",
        "\n",
        "Let’s first look at the inputs. You have in total two inputs:\n",
        "- `source_words`: the word indices of the sentences in the source language. This input has the shape `[batch_size, max_source_sent_len]` during both training and inference.\n",
        "- `target_words`: the word indices of the sentences in the target language. During training, this input will have the shape `[batch_size, max_target_sent_len]`, but during the inference, it will have the shape `[batch_size, 1]`.\n",
        "\n",
        "You will need to first create two `nn.Embedding` layers `embedding_source` and `embedding_target`. The Embedding layers will randomly initialise the embeddings for individual words in the vocabulary and the embeddings will be trained together with the network.  The `nn.Embedding` layers have an `input_dim` of the `vocab_size` and an `output_dim` of the `embedding_size`.  Please note the `vocab_size` for the source and the target language are different. Also, you will need to set the `padding_idx` in order to ignore the paddings.\n",
        "  \n",
        "Secondly, you need to look up the embeddings for the current inputs (`source_words` and `target_words`) by passing them through the `nn.Embedding` layers you created. The embeddings for source and target words need to be called `source_words_embeddings` and `target_words_embeddings` respectively.\n",
        "\n",
        "Thirdly, you can create an `nn.LSTM` layer to process the `source_words_embeddings`, you will need to set the `bidirectional` to `False` and set the `batch_first` to `True`."
      ],
      "metadata": {
        "id": "hU8QeFB8jfEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NmtModel(nn.Module):\n",
        "    def __init__(self, source_dict, target_dict, use_attention):\n",
        "        \"\"\"\n",
        "        Initializes the NMT Model hyperparameters and layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.source_dict = source_dict\n",
        "        self.target_dict = target_dict\n",
        "        self.use_attention = use_attention\n",
        "\n",
        "        # Hyperparams\n",
        "        self.hidden_size = 200\n",
        "        self.embedding_size = 100\n",
        "        self.hidden_dropout_rate = 0.2\n",
        "        self.embedding_dropout_rate = 0.2\n",
        "        self.batch_size = 100\n",
        "        self.max_target_step = 30\n",
        "\n",
        "        # Special tokens\n",
        "        self.SOS = target_dict.word2ids['<start>']\n",
        "        self.EOS = target_dict.word2ids['<end>']\n",
        "\n",
        "        # Vocab sizes\n",
        "        self.vocab_source_size = len(source_dict.vocab)\n",
        "        self.vocab_target_size = len(target_dict.vocab)\n",
        "\n",
        "        print(f\"number of tokens in source: {self.vocab_source_size}, \"\n",
        "              f\"number of tokens in target: {self.vocab_target_size}\")\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        Task 1: Implementing the encoder 1/2\n",
        "\n",
        "        Begin\n",
        "        \"\"\"\n",
        "\n",
        "        # embeddings for source and target with padding_idx specified\n",
        "        self.embedding_source = nn.Embedding(self.vocab_source_size, self.embedding_size, padding_idx=source_dict.PAD)\n",
        "        self.embedding_target = nn.Embedding(self.vocab_target_size, self.embedding_size, padding_idx=target_dict.PAD)\n",
        "\n",
        "\n",
        "        # encoder lstm layer\n",
        "        self.encoder_lstm = nn.LSTM(input_size=self.embedding_size,hidden_size=self.hidden_size,num_layers=1,batch_first=True,dropout=self.hidden_dropout_rate,bidirectional=False)\n",
        "        \"\"\"\n",
        "        End Task 1 1/2\n",
        "        \"\"\"\n",
        "\n",
        "        # Decoder LSTM\n",
        "        self.decoder_lstm = nn.LSTM(\n",
        "            input_size=self.embedding_size,\n",
        "            hidden_size=self.hidden_size,\n",
        "            num_layers=1,\n",
        "            batch_first=True,\n",
        "            dropout=self.hidden_dropout_rate,\n",
        "            bidirectional=False\n",
        "        )\n",
        "\n",
        "        # Attention (if use_attention)\n",
        "        if self.use_attention:\n",
        "            self.decoder_attention = AttentionLayer()\n",
        "\n",
        "        # Final projection\n",
        "        # If attention, hidden_size * 2, else hidden_size\n",
        "        if self.use_attention:\n",
        "            self.decoder_dense = nn.Linear(self.hidden_size*2, self.vocab_target_size)\n",
        "        else:\n",
        "            self.decoder_dense = nn.Linear(self.hidden_size, self.vocab_target_size)"
      ],
      "metadata": {
        "id": "iTAcrIj2jo8d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUfzuQZ2urbf"
      },
      "source": [
        "## NmtModel `forward()`, `decode_step()` and `encode()` methods:  builds the PyTorch models for training and inference.\n",
        "The method first creates the inputs for both training and inference models, which include the source/target sentence batches; The inputs specifically used for the inference models are defined later.\n",
        "\n",
        "Task 1 will be to create embeddings for both source/target languages as well as the encoder. We will discuss this in a later section.\n",
        "\n",
        "After that, we define the decoder used for the training. In NMT separate decoders are often used for training and inference. During training, we feed the ground truth tokens into the decoder (teacher forcing), hence we process all tokens in the sentences in a single step. During inference, the system processes one token at a time, and the token predicted at the current step will be used as the input for the next step.  More specifically, the size of `target_words` will be `[batch, max_sent_len]` during training and `[batch, 1]` during inference. The training and inference models behave slightly differently, but they share all the layers (`decoder_lstm, decoder_attention and decoder_dense`);\n",
        "\n",
        "Task 2 will be to implement the decoder for inference. We will discuss this later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "AswJ_KkNurbf"
      },
      "outputs": [],
      "source": [
        "class NmtModel(NmtModel):\n",
        "    def forward(self, source_words, target_words):\n",
        "        \"\"\"\n",
        "        Forward pass for training:\n",
        "          1) Encode the source sentences using the encoder LSTM.\n",
        "          2) Use the final encoder state to initialize the decoder's hidden state.\n",
        "          3) Feed all target words into the decoder LSTM in one go (teacher forcing).\n",
        "          4) (Optional) apply the attention layer between the decoder outputs and the encoder outputs.\n",
        "          5) Project the decoder outputs to vocabulary logits with self.proj.\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        Task 1: Implementing the encoder 2/2\n",
        "\n",
        "        Begin\n",
        "        \"\"\"\n",
        "\n",
        "        #embedding lookup\n",
        "        source_words_embeddings = self.embedding_source(source_words)  # [batch_size, max_source_len, embedding_size]\n",
        "        target_words_embeddings = self.embedding_target(target_words)  # [batch_size, max_target_len, embedding_size]\n",
        "\n",
        "\n",
        "\n",
        "        #encoding source words\n",
        "        encoder_outputs, (enc_h, enc_c) = self.encoder_lstm(source_words_embeddings)\n",
        "\n",
        "        #teacher forcing\n",
        "        decoder_outputs, _ = self.decoder_lstm(target_words_embeddings, (enc_h, enc_c))\n",
        "\n",
        "        # if attention is used\n",
        "        if self.use_attention:\n",
        "            print(\"applying attention\")\n",
        "            decoder_outputs = self.decoder_attention(encoder_outputs, decoder_outputs)\n",
        "            if decoder_outputs is None:\n",
        "              raise ValueError(\"decoder_outputs is none after attention!\")\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        End Task 1 2/2\n",
        "        \"\"\"\n",
        "\n",
        "        # 5) Projection\n",
        "        decoder_outputs = self.decoder_dense(decoder_outputs)  # [batch, max_tgt_len, vocab_target_size]\n",
        "        return decoder_outputs\n",
        "\n",
        "    def decode_step(self, target_words, decoder_states, encoder_outputs):\n",
        "        \"\"\"\n",
        "        A single step of decoder inference:\n",
        "          - Embedding for the current token\n",
        "          - One-step LSTM forward\n",
        "          - (Optional) attention over encoder outputs\n",
        "          - Project to vocab\n",
        "        Inputs:\n",
        "          tgt_input: shape [batch_size, 1]\n",
        "          decoder_states: (dec_h, dec_c) each is [1, batch_size, hidden_size]\n",
        "          encoder_outputs: [batch_size, max_src_len, hidden_size]\n",
        "        Returns:\n",
        "          logits for the next token, and the new decoder states\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        Task 2: Implementing the decoder and the inference loop\n",
        "        In this task, you will work on the decode_step() method.\n",
        "\n",
        "The decoder for inference is similar to the encoder for training but it only performs one step of the decoding at a time.\n",
        " Remember the decoders share all the layers, you will need to use the layers created in the decoder for training.\n",
        "  In total three layers are used in both decoders. These are the decoder_lstm (the decoder nn.LSTM layer),\n",
        "   decoder_dense (the decoder final layer) and the decoder_attention (the attention layer for the attention based model) layers.\n",
        "\n",
        "First, unlike the decoder for training that uses the encoder_states (enc_h, enc_c) as the hidden_size for decoder_lstm, we need to use the decoder states from the previous step instead (dec_h, dec_c). You need to put them together in a list to create the decoder_states. If you take a look at the eval_process method you will find out that for the first step, the decoder_states passed into the model are actually the encoder_states (same as in the decoder during training), while in the subsequent steps the decoder_states become the ones the decoder_states returns in the previous step.\n",
        "\n",
        "Secondly, you will need to pass the target_word_embeddings and decoder_states to the decoder_lstm.\n",
        "\n",
        "Thirdly you will write an if statement for the attention model just like we did in the decoder for training.\n",
        "\n",
        "Finally, pass the output of the nn.LSTM (for basic model) or the attention layer (for attention model) into the final linear layer of the decoder (decoder_dense) to get probabilities for the next token.\n",
        "\n",
        "You have now a functional NMT system, why not test it out to see how well it works. Please note you need to set the use_attention to False since you haven’t implemented the attention layer yet. The system will take about a minute to finish 10 epochs of training and you will get a BLEU score of around 4.\n",
        "\n",
        "        Begin\n",
        "        \"\"\"\n",
        "        #embedding lookup for the current target token [batch_size, 1, embedding_size]\n",
        "        target_words_embeddings = self.embedding_target(target_words)\n",
        "\n",
        "        # LSTM step using previous decoder states\n",
        "        decoder_outputs, (dec_h, dec_c) = self.decoder_lstm(target_words_embeddings, decoder_states)\n",
        "\n",
        "        #if attention is used\n",
        "        if self.use_attention:\n",
        "            decoder_outputs = self.decoder_attention(encoder_outputs, decoder_outputs)\n",
        "            if decoder_outputs is None:\n",
        "                raise ValueError(\"decoder_outputs is None after attention!\")\n",
        "\n",
        "        #projecting to vocabulary space [batch, 1, vocab_target_size]\n",
        "        decoder_outputs = self.decoder_dense(decoder_outputs)\n",
        "\n",
        "        \"\"\"\n",
        "        End Task 2\n",
        "        \"\"\"\n",
        "\n",
        "        return decoder_outputs, (dec_h, dec_c)\n",
        "\n",
        "    def encode(self, source_words):\n",
        "        \"\"\"\n",
        "        Encode the source sequence once for inference.\n",
        "        \"\"\"\n",
        "        source_words_embeddings = F.dropout(self.embedding_source(source_words), p=self.embedding_dropout_rate, training=False)\n",
        "        encoder_outputs, (enc_h, enc_c) = self.encoder_lstm(source_words_embeddings)\n",
        "        return encoder_outputs, (enc_h, enc_c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WCkE2Glurbf"
      },
      "source": [
        "## NmtModel, `time_used()` method: outputs the time differences between the current time and the input time.\n",
        "It is always good practice to record the time usage of an individual process, so you always know which part is most expensive to run."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NmtModel(NmtModel):\n",
        "  def time_used(self, start_time):\n",
        "          \"\"\"\n",
        "          Outputs the time differences between now and start_time.\n",
        "          \"\"\"\n",
        "          curr_time = time.time()\n",
        "          used_time = curr_time - start_time\n",
        "          m = int(used_time // 60)\n",
        "          s = int(used_time - 60 * m)\n",
        "          return f\"{m} m {s} s\""
      ],
      "metadata": {
        "id": "3c3KYfpPYrqR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA1Tepyyurbf"
      },
      "source": [
        "## The `get_target_sentences()` method takes sentence indices and returns the string tokens.\n",
        "The method is a helper for the `eval_process` method, which is used to create reference and candidate sentences for evaluation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Wr6Y0nF0urbf"
      },
      "outputs": [],
      "source": [
        "class NmtModel(NmtModel):\n",
        "    def get_target_sentences(self, sents, vocab):\n",
        "        \"\"\"\n",
        "        Convert a batch of sequences of token-IDs into strings.\n",
        "        Stop at <end> or skip <start>.\n",
        "        \"\"\"\n",
        "        str_sents = []\n",
        "        num_sent, max_len = sents.shape\n",
        "        for i in range(num_sent):\n",
        "            str_sent = []\n",
        "            for j in range(max_len):\n",
        "                t = int(sents[i, j])\n",
        "                if t == self.SOS:\n",
        "                    continue\n",
        "                if t == self.EOS:\n",
        "                    break\n",
        "                str_sent.append(vocab[t])\n",
        "            str_sents.append(\" \".join(str_sent))\n",
        "        return str_sents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiE72Tb6urbf"
      },
      "source": [
        "## NmtModel, `eval_process()` method: runs evaluation on the given dataset.\n",
        "The method first translates the source sentences into the target language, and then compares them to the reference sentences. As a result, it outputs standard BLEU scores (as computed by the state-of-the-art Sacrebleu (https://github.com/mjpost/sacrebleu) implementation). Note that here we do not tokenise our outputs and references as they are already tokenised and we compare the models internally. However, to ensure comparability to other published work for the same data you need to detokenise your outputs and then use the default tokenisation with the argument `tokenize=BLEU.TOKENIZER_DEFAULT`.\n",
        "\n",
        "*`eval()` method and exist in `nn.module`, used to convert the model into a evaluation mode. for example turning off dropout*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detokenize(sentence_ids, vocab):\n",
        "    \"\"\"\n",
        "    Convert a list of token IDs back into a readable sentence using the vocabulary in order to understand the input sentence.\n",
        "    \"\"\"\n",
        "    words = [vocab[idx] if idx < len(vocab) else \"<unk>\" for idx in sentence_ids]\n",
        "    return \" \".join(words)"
      ],
      "metadata": {
        "id": "_MOEY8oRqlrg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "BoIueiRYurbg"
      },
      "outputs": [],
      "source": [
        "import html\n",
        "class NmtModel(NmtModel):\n",
        "    def eval_process(self, dataset):\n",
        "        \"\"\"\n",
        "        Evaluate on a given dataset, returning a BLEU score.\n",
        "        \"\"\"\n",
        "        self.eval()  # set model to eval mode, turning off dropout\n",
        "\n",
        "        source_words, target_words_labels = dataset\n",
        "        device = next(self.parameters()).device\n",
        "\n",
        "        # Convert to torch\n",
        "        source_words_torch = torch.LongTensor(source_words).to(device)\n",
        "        target_words_labels_torch = torch.LongTensor(target_words_labels).to(device)\n",
        "\n",
        "        # 1) Encode\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs, (enc_h, enc_c) = self.encode(source_words_torch)\n",
        "\n",
        "        batch_size = source_words_torch.size(0)\n",
        "        # Start tokens => shape [batch_size, 1]\n",
        "        step_tgt = torch.LongTensor([self.SOS]*batch_size).unsqueeze(1).to(device)\n",
        "        decoder_states = (enc_h, enc_c)\n",
        "\n",
        "        predictions = []\n",
        "        # 2) decode up to max_target_step\n",
        "        for _ in range(self.max_target_step):\n",
        "            with torch.no_grad():\n",
        "                logits, decoder_states = self.decode_step(step_tgt, decoder_states, encoder_outputs)\n",
        "            # argmax over vocab\n",
        "            step_tgt = torch.argmax(logits, dim=-1)  # [batch_size, 1]\n",
        "            predictions.append(step_tgt.cpu().numpy())\n",
        "\n",
        "        # Convert predictions => [batch, max_target_step]\n",
        "        predictions = np.concatenate(predictions, axis=1)\n",
        "        # Convert to strings\n",
        "        candidates = self.get_target_sentences(predictions, self.target_dict.vocab)\n",
        "        references = self.get_target_sentences(target_words_labels_torch.cpu().numpy(), self.target_dict.vocab)\n",
        "\n",
        "        # Fix tokenization issues\n",
        "        candidates = [html.unescape(sent) for sent in candidates]\n",
        "        references = [html.unescape(sent) for sent in references]\n",
        "\n",
        "\n",
        "        # Score with sacrebleu\n",
        "        score = corpus_bleu(candidates, [references], tokenize='none').score\n",
        "        print(f\"Model BLEU score: {score:.2f}\")\n",
        "\n",
        "\n",
        "        print(\"\\n Sample Translations:\")\n",
        "        for i in range(5):  # Print first 5 samples\n",
        "            #print(f\"input (Vietnamese): {detokenize(source_words[i], self.source_dict.vocab)}\")\n",
        "            print(f\"predicted Translation: {candidates[i]}\")\n",
        "            print(f\"reference Translation: {references[i]}\\n\")\n",
        "\n",
        "\n",
        "        return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM7ndsBLurbg"
      },
      "source": [
        "## The `train_main` method starts the training.\n",
        "Please note you will need to change the argument of the `use_attention` parameter accordingly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "TCHCgLGFurbg"
      },
      "outputs": [],
      "source": [
        "class NmtModel(NmtModel):\n",
        "    def train_model(self, train_data, dev_data, test_data, epochs=10, lr=0.01, clip_norm=5.0, device='cpu'):\n",
        "        \"\"\"\n",
        "        Oversees the training process.\n",
        "        1) For each epoch, train on the entire training dataset.\n",
        "        2) Evaluate on dev data after each epoch.\n",
        "        3) Finally evaluate on test data.\n",
        "        \"\"\"\n",
        "        self.to(device)\n",
        "        optimizer = optim.Adam(self.parameters(), lr=lr)\n",
        "        loss_fn = nn.CrossEntropyLoss(ignore_index=self.target_dict.PAD)\n",
        "\n",
        "        # Unpack data\n",
        "        source_words_train, target_words_train, target_words_train_labels = train_data\n",
        "        source_words_dev,   target_words_dev_labels = dev_data\n",
        "        source_words_test,  target_words_test_labels = test_data\n",
        "\n",
        "        # For convenience, convert all to torch on CPU first\n",
        "        source_words_train_torch = torch.LongTensor(source_words_train)\n",
        "        target_words_train_torch = torch.LongTensor(target_words_train)\n",
        "        target_words_train_labels_torch = torch.LongTensor(target_words_train_labels.squeeze(-1))  # [batch, max_len]\n",
        "\n",
        "        # We won't build a fancy DataLoader here; just run with entire batch or smaller mini-batches\n",
        "        num_samples = source_words_train_torch.size(0)\n",
        "        idx_list = np.arange(num_samples)\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        for epoch in range(1, epochs+1):\n",
        "            print(f\"Starting training epoch {epoch}/{epochs}\")\n",
        "            epoch_time = time.time()\n",
        "\n",
        "            # Shuffle data\n",
        "            np.random.shuffle(idx_list)\n",
        "\n",
        "            # Mini-batch training\n",
        "            self.train()  # set model to train mode\n",
        "            batch_size = self.batch_size\n",
        "            for start_idx in range(0, num_samples, batch_size):\n",
        "                end_idx = start_idx + batch_size\n",
        "                excerpt = idx_list[start_idx:end_idx]\n",
        "\n",
        "                src_batch = source_words_train_torch[excerpt].to(device)\n",
        "                tgt_batch = target_words_train_torch[excerpt].to(device)\n",
        "                tgt_labels_batch = target_words_train_labels_torch[excerpt].to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                logits = self.forward(src_batch, tgt_batch)  # [batch, tgt_len, vocab_size]\n",
        "\n",
        "                # Flatten for cross entropy\n",
        "                # logits: [batch*tgt_len, vocab_size]\n",
        "                # labels: [batch*tgt_len]\n",
        "                logits_2d = logits.view(-1, logits.size(-1))\n",
        "                labels_2d = tgt_labels_batch.view(-1)\n",
        "\n",
        "                loss = loss_fn(logits_2d, labels_2d)\n",
        "                loss.backward()\n",
        "\n",
        "                # Clip gradients\n",
        "                torch.nn.utils.clip_grad_norm_(self.parameters(), clip_norm)\n",
        "                optimizer.step()\n",
        "\n",
        "            print(f\"Time used for epoch {epoch}: {self.time_used(epoch_time)}\")\n",
        "\n",
        "            # Evaluate on dev\n",
        "            print(f\"Evaluating on dev set after epoch {epoch}/{epochs}:\")\n",
        "            self.eval_process([source_words_dev, target_words_dev_labels])\n",
        "\n",
        "        # Training finished\n",
        "        print(\"Training finished!\")\n",
        "        print(f\"Time used for training: {self.time_used(start_time)}\")\n",
        "\n",
        "        # Evaluate on test set\n",
        "        print(\"Evaluating on test set:\")\n",
        "        self.eval_process([source_words_test, target_words_test_labels])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main(source_path, target_path, use_attention=True):\n",
        "    max_example = 30000\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(\"loading dictionaries...\")\n",
        "    train_data, dev_data, test_data, source_dict, target_dict = load_dataset(\n",
        "        source_path, target_path, max_num_examples=max_example\n",
        "    )\n",
        "    print(f\"read {len(train_data[0])}/{len(dev_data[0])}/{len(test_data[0])} train/dev/test batches\")\n",
        "\n",
        "    # Create model\n",
        "    model = NmtModel(source_dict, target_dict, use_attention=use_attention)\n",
        "    # Train\n",
        "    model.train_model(train_data, dev_data, test_data, epochs=10, lr=0.01, clip_norm=5.0, device=device)"
      ],
      "metadata": {
        "id": "UNQdFsBP59G1"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzUuaxvHurbg"
      },
      "source": [
        "## Task 1: Implement the Embedding Layers and the Encoder\n",
        "In this task, you will work at the beginning of the `__init__()` and `forward()` method. You will need to first create two `nn.Embedding` layers (one for the source language and one for the target language). Then pass the source embedding into an `nn.LSTM` layer.\n",
        "\n",
        "Let’s first look at the inputs. You have in total two inputs:\n",
        "- `source_words`: the word indices of the sentences in the source language. This input has the shape `[batch_size, max_source_sent_len]` during both training and inference.\n",
        "- `target_words`: the word indices of the sentences in the target language. During training, this input will have the shape `[batch_size, max_target_sent_len]`, but during the inference, it will have the shape `[batch_size, 1]`.\n",
        "\n",
        "You will need to first create two `nn.Embedding` layers `embedding_source` and `embedding_target`. The Embedding layers will randomly initialise the embeddings for individual words in the vocabulary and the embeddings will be trained together with the network.  The `nn.Embedding` layers have an `input_dim` of the `vocab_size` and an `output_dim` of the `embedding_size`.  Please note the `vocab_size` for the source and the target language are different. Also, you will need to set the `padding_idx` in order to ignore the paddings.\n",
        "  \n",
        "Secondly, you need to look up the embeddings for the current inputs (`source_words` and `target_words`) by passing them through the `nn.Embedding` layers you created. The embeddings for source and target words need to be called `source_words_embeddings` and `target_words_embeddings` respectively.\n",
        "\n",
        "Thirdly, you can create an `nn.LSTM` layer to process the `source_words_embeddings`, you will need to set the `bidirectional` to `False` and set the `batch_first` to `True`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_QsyuNQurbg"
      },
      "source": [
        "## Task 2: Implement the Decoder for inference\n",
        "In this task, you will work on the `decode_step()` method.\n",
        "\n",
        "The decoder for inference is similar to the encoder for training but it only performs one step of the decoding at a time. Remember the decoders share all the layers, you will need to use the layers created in the decoder for training. In total three layers are used in both decoders. These are the `decoder_lstm` (the decoder nn.LSTM layer), `decoder_dense` (the decoder final layer) and the `decoder_attention` (the attention layer for the attention based model) layers.\n",
        "\n",
        "First, unlike the decoder for training that uses the `encoder_states` (`enc_h`, `enc_c`) as the `hidden_size` for `decoder_lstm`, we need to use the decoder states from the previous step instead (`dec_h`, `dec_c`).  You need to put them together in a list to create the `decoder_states`. If you take a look at the `eval_process` method you will find out that for the first step, the `decoder_states` passed into the model are actually the `encoder_states` (same as in the decoder during training), while in the subsequent steps the `decoder_states` become the ones the `decoder_states` returns in the previous step.\n",
        "\n",
        "Secondly, you will need to pass the `target_word_embeddings` and `decoder_states` to the `decoder_lstm`.\n",
        "\n",
        "Thirdly you will write an if statement for the attention model just like we did in the decoder for training.\n",
        "\n",
        "Finally, pass the output of the nn.LSTM (for basic model) or the attention layer (for attention model) into the final linear layer of the decoder (`decoder_dense`) to get probabilities for the next token.\n",
        "\n",
        "You have now a functional NMT system, why not test it out to see how well it works. Please note you need to set the `use_attention` to `False` since you haven’t implemented the attention layer yet.  The system will take about a minute to finish 10 epochs of training and you will get a BLEU score of around 4.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IsO7wW6U1w2m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7d5405-e92e-4766-c3fd-e9b89f55d41a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading dictionaries...\n",
            "read 24000/3000/3000 train/dev/test batches\n",
            "number of tokens in source: 2034, number of tokens in target: 2506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training epoch 1/10\n",
            "Time used for epoch 1: 0 m 2 s\n",
            "Evaluating on dev set after epoch 1/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 1.74\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: and i 'm going to <unk> the <unk> of the <unk> , and the <unk> of the <unk> .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: and i 'm going to <unk> the <unk> of the <unk> , and the <unk> of the <unk> .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: and i 'm going to <unk> the <unk> of the <unk> , and the <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and i 'm going to <unk> the <unk> of the <unk> , and the <unk> of the <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: and i 'm going to <unk> the <unk> of the <unk> , and the <unk> of the <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 2/10\n",
            "Time used for epoch 2: 0 m 2 s\n",
            "Evaluating on dev set after epoch 2/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 1.15\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: so i 'm <unk> , and i 'm a <unk> .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: and i think we 're <unk> to <unk> , and i 'm a <unk> .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: so i 'm <unk> , and i 'm a <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and i think , you know , <unk> , <unk> , <unk> , <unk> , <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: so i 'm <unk> , and i 'm a <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 3/10\n",
            "Time used for epoch 3: 0 m 2 s\n",
            "Evaluating on dev set after epoch 3/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 1.97\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: now , i 'm not sure you can do it .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but it 's not a <unk> <unk> .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: it 's not a <unk> <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and the <unk> <unk> <unk> <unk> <unk> , <unk> , <unk> , <unk> , <unk> , <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: it 's not a <unk> <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 4/10\n",
            "Time used for epoch 4: 0 m 2 s\n",
            "Evaluating on dev set after epoch 4/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 2.99\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: it 's not a <unk> <unk> <unk> , and it 's not a <unk> <unk> <unk> .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but it 's not a <unk> <unk> .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: it 's a <unk> <unk> of <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and you know , it 's not a <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: it 's a <unk> <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 5/10\n",
            "Time used for epoch 5: 0 m 2 s\n",
            "Evaluating on dev set after epoch 5/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 3.27\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: there 's a lot of <unk> in the world of <unk> and <unk> <unk> .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but it 's not just the first <unk> .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: it 's not about selling <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and the <unk> <unk> is <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: this is the <unk> <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 6/10\n",
            "Time used for epoch 6: 0 m 2 s\n",
            "Evaluating on dev set after epoch 6/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 3.57\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: there 's a lot of <unk> in the <unk> , and it 's <unk> , and it 's <unk> .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but this is a <unk> <unk> .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: he 's <unk> <unk> , and the <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and the <unk> is <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: this is a <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 7/10\n",
            "Time used for epoch 7: 0 m 2 s\n",
            "Evaluating on dev set after epoch 7/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 3.95\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: there 's a <unk> <unk> , and there 's a <unk> <unk> , and there 's a <unk> <unk> .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but it 's a <unk> .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: the <unk> is <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and you can see the <unk> of the <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: there 's a <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 8/10\n",
            "Time used for epoch 8: 0 m 2 s\n",
            "Evaluating on dev set after epoch 8/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 3.91\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: there 's a <unk> <unk> , and it 's <unk> , and it 's <unk> , but it 's <unk> .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but this is a <unk> .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: it 's a <unk> <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and you can see the <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: this is a <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 9/10\n",
            "Time used for epoch 9: 0 m 2 s\n",
            "Evaluating on dev set after epoch 9/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 4.34\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: there 's a <unk> <unk> , and it 's <unk> , but it 's <unk> , but it 's <unk> .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but here 's the <unk> thing .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: it 's like the <unk> of the <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and you can see the <unk> of the <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: this is the <unk> <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 10/10\n",
            "Time used for epoch 10: 0 m 2 s\n",
            "Evaluating on dev set after epoch 10/10:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 4.35\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: it 's a <unk> <unk> , and it 's <unk> , <unk> , <unk> , <unk> , <unk> , <unk> .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but this is the <unk> <unk> .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: the <unk> is <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and now , in the <unk> condition , you can see the <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: this is the <unk> <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Training finished!\n",
            "Time used for training: 0 m 28 s\n",
            "Evaluating on test set:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 4.46\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: the <unk> <unk> <unk> <unk> <unk> <unk> <unk> , and it 's <unk> .\n",
            "reference Translation: the second quote is from the head of the u.k. financial services <unk> .\n",
            "\n",
            "predicted Translation: it 's <unk> .\n",
            "reference Translation: it gets worse .\n",
            "\n",
            "predicted Translation: what 's the <unk> of the <unk> that we can do is <unk> ?\n",
            "reference Translation: what 's happening here ? how can this be possible ?\n",
            "\n",
            "predicted Translation: well , it 's not a <unk> .\n",
            "reference Translation: unfortunately , the answer is yes .\n",
            "\n",
            "predicted Translation: but <unk> , <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> .\n",
            "reference Translation: but there 's an <unk> solution which is coming from what is known as the science of <unk> .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "main(SOURCE_PATH, TARGET_PATH, use_attention=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlMDC3DJi12c"
      },
      "source": [
        "## Task 3: Implement the Attention layer\n",
        "In this task, you will work on the `forward` method of the `AttentionLayer` class.\n",
        "\n",
        "The attention decoder is the secret recipe for the success of the NMT. It enables the decoder to access all the encoder outputs and focus on their different parts during different steps. By contrast, the basic model only has access to the final states of the encoder. There are a few different ways to build an attention mechanism. Here we build an attention mechanism similar to the one proposed by Luong et al. (2015), which computes the score between `decoder_outputs` and `encoder_outputs` by dot product.\n",
        "\n",
        "First, let’s take a look at the shape of our inputs (`encoder_outputs, decoder_outputs`). `encoder_outputs` has a shape of `[batch_size, max_source_sent_len, hidden_size]`. `decoder_outputs` has a shape of `[batch_size, max_target_sent_len, hidden_size]`. In order to multiply them, we need to first transpose the last two dimensions of `decoder_outputs` to make its shape become `[batch_size, hidden_size, max_target_sent_len]`. You will need to use the backend `permute_dimensions` method to do this.\n",
        "\n",
        "Once the `decoder_output` is transposed we use the `batch_dot` to compute the dot product. Let’s call the output `luong_score`. It has a shape of `[batch_size, max_source_sent_len, max_target_sent_len]` then you need apply a softmax to the dimension that have a size of `max_source_sent_len` to create an attention score for the `encoder_outputs`.   \n",
        "\n",
        "Finally, we are going to create the `encoder_vector` by doing element-wise multiplication between the `encoder_outputs` and their attention scores (`luong_score`). But as you may have noticed the shape of `luong_score` is actually not the same as that of `encoder_outputs`, so we need to use the `expand_dims` method to expand dimensions for both of them. For  `luong_score`, you need to expand the last dimension to accommodate the `hidden_size` dimension of `encoder_outputs`. So after expansion, the shape becomes `[batch_size, max_source_sent_len, max_target_sent_len, 1]`. For  `encoder_outputs`, the target shape is `[batch_size, max_source_sent_len, 1, hidden_size]`. When multiplying between the two tensors, the expanded dimensions will be broadcasted so that they have the same shape. The last step is to sum along the `max_source_sent_len` dimension to create the `encoder_vector`.\n",
        "\n",
        "Before returning the `new_decoder_outputs` we concatenate the `decoder_outputs` and the `encoder_vector` using the concatenate method (the code is already provided).\n",
        "\n",
        "You’ve created an attention NMT system, let’s run your code (remember to set `use_attention` to True), it will take about a minute on a GPU to train it and you will get a much better BLEU score, usually above 12 (three times better than the score for the basic version)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "23t6wfpLkb2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "399a288b-aed9-4baf-8631-0376007e1d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading dictionaries...\n",
            "read 24000/3000/3000 train/dev/test batches\n",
            "number of tokens in source: 2034, number of tokens in target: 2506\n",
            "Starting training epoch 1/10\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "Time used for epoch 1: 0 m 3 s\n",
            "Evaluating on dev set after epoch 1/10:\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 9.90\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: there are some <unk> , to <unk> , it 's going to be <unk> , it 's going to be <unk> .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but this is really the beginning of the beginning .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: the <unk> <unk> <unk> <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and the <unk> is a <unk> that there are a <unk> <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: this is the <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 2/10\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "Time used for epoch 2: 0 m 3 s\n",
            "Evaluating on dev set after epoch 2/10:\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 12.17\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: there 's four <unk> , to each other , and each of the <unk> , it 's <unk> <unk> .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but this is actually the beginning of this .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: the <unk> approach around the <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and you can see here is the <unk> of <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: this is the <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 3/10\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "Time used for epoch 3: 0 m 3 s\n",
            "Evaluating on dev set after epoch 3/10:\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Model BLEU score: 13.33\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: there 's four <unk> , which is a <unk> , which is a <unk> of the <unk> , it 's <unk> .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but here 's actually the <unk> .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: the <unk> <unk> <unk> <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and you can see here is the <unk> <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: this particular <unk> of this <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 4/10\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "Time used for epoch 4: 0 m 3 s\n",
            "Evaluating on dev set after epoch 4/10:\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 14.46\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: there are four <unk> to <unk> , and every <unk> , it 's <unk> when it <unk> behind the <unk> .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but this is actually just beginning .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: <unk> <unk> : the <unk> <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and you can see here is the <unk> <unk> <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: this is the <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 5/10\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "Time used for epoch 5: 0 m 3 s\n",
            "Evaluating on dev set after epoch 5/10:\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Model BLEU score: 14.39\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: there 's four <unk> , to each other , to each other , to each other , it 's <unk> <unk> , it 's a <unk> shape .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but this is really just beginning .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: the <unk> is made the <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and you can see here is the <unk> <unk> <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: this is a <unk> <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 6/10\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "Time used for epoch 6: 0 m 3 s\n",
            "Evaluating on dev set after epoch 6/10:\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 14.10\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: there 's four different areas of <unk> , which gives it back to you , it 's <unk> when it was <unk> .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but this is actually the beginning .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: it 's <unk> by <unk> <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and you can see here is the <unk> <unk> on the <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: this is <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 7/10\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "Time used for epoch 7: 0 m 3 s\n",
            "Evaluating on dev set after epoch 7/10:\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Model BLEU score: 13.86\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: there are four , to every <unk> , and it 's <unk> when it <unk> up behind the location , it 's <unk> .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but it 's actually just <unk> .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: <unk> <unk> <unk> <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and you can see here is the <unk> <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: this one needs to express <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 8/10\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "Time used for epoch 8: 0 m 3 s\n",
            "Evaluating on dev set after epoch 8/10:\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 13.88\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: there 's four , to <unk> , to <unk> when it <unk> when it <unk> when it <unk> up in the <unk> shape .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but this really starts the beginning of the <unk> .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: the <unk> has been <unk> the axis of <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and you can see that this is the <unk> <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: this particular expression of led to <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 9/10\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "Time used for epoch 9: 0 m 3 s\n",
            "Evaluating on dev set after epoch 9/10:\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 13.68\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: there 's four <unk> to remote <unk> when it 's <unk> when it was <unk> , it 's a <unk> display on the mind .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but it 's just a really <unk> thing .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: the <unk> is <unk> the axis of <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and you can see here is the <unk> <unk> <unk> .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: this can be <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Starting training epoch 10/10\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "applying attention\n",
            "Attention decoder outputs shape: torch.Size([100, 31, 400])\n",
            "Time used for epoch 10: 0 m 3 s\n",
            "Evaluating on dev set after epoch 10/10:\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 13.72\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: there 's four , which <unk> to every <unk> , it 's a <unk> that goes back when it <unk> on shape .\n",
            "reference Translation: there are four <unk> <unk> that , each time this ring <unk> it , as it <unk> the <unk> of the display , it <unk> up a position signal .\n",
            "\n",
            "predicted Translation: but it 's really really <unk> .\n",
            "reference Translation: but this is really just the beginning .\n",
            "\n",
            "predicted Translation: it 's evidence that <unk> <unk> .\n",
            "reference Translation: it <unk> this by <unk> <unk> about two <unk> .\n",
            "\n",
            "predicted Translation: and you can see here is the <unk> board that reward .\n",
            "reference Translation: so as you can see here , this is a , <unk> <unk> <unk> board .\n",
            "\n",
            "predicted Translation: this is <unk> .\n",
            "reference Translation: these blocks <unk> <unk> .\n",
            "\n",
            "Training finished!\n",
            "Time used for training: 0 m 40 s\n",
            "Evaluating on test set:\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n",
            "Attention decoder outputs shape: torch.Size([3000, 1, 400])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model BLEU score: 14.00\n",
            "\n",
            " Sample Translations:\n",
            "predicted Translation: in the first few of the <unk> first <unk> comes from the first business comes from the way .\n",
            "reference Translation: the second quote is from the head of the u.k. financial services <unk> .\n",
            "\n",
            "predicted Translation: so , it 's more <unk> .\n",
            "reference Translation: it gets worse .\n",
            "\n",
            "predicted Translation: what 's happening in here ? why are you ? \"\n",
            "reference Translation: what 's happening here ? how can this be possible ?\n",
            "\n",
            "predicted Translation: unfortunately , unfortunately , the answer is yes .\n",
            "reference Translation: unfortunately , the answer is yes .\n",
            "\n",
            "predicted Translation: but in fact , there 's a very interesting solution from the age of doing science .\n",
            "reference Translation: but there 's an <unk> solution which is coming from what is known as the science of <unk> .\n",
            "\n"
          ]
        }
      ],
      "source": [
        "main(SOURCE_PATH, TARGET_PATH, use_attention=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}